# REQ-4: Äá» TÃ i Cuá»‘i Ká»³ - PhÃ¢n VÃ¹ng NgÆ°á»i & PhÃ¡t Hiá»‡n XÃ¢m Nháº­p Khu Vá»±c Cáº¥m

## ThÃ´ng Tin Äá» TÃ i

**TÃªn Äá» TÃ i**: PhÃ¢n VÃ¹ng NgÆ°á»i & PhÃ¡t Hiá»‡n XÃ¢m Nháº­p Khu Vá»±c Cáº¥m
**MÃ£ Sá»‘**: Topic 43
**MÃ´n Há»c**: Xá»­ LÃ½ áº¢nh
**NÄƒm Há»c**: 2024-2025

---

## Tá»•ng Quan

Äá» tÃ i nÃ y táº­p trung vÃ o xÃ¢y dá»±ng há»‡ thá»‘ng **phÃ¡t hiá»‡n vÃ  cáº£nh bÃ¡o** khi cÃ³ ngÆ°á»i xÃ¢m nháº­p vÃ o khu vá»±c bá»‹ cáº¥m sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t xá»­ lÃ½ áº£nh vÃ  computer vision. Há»‡ thá»‘ng cáº§n hoáº¡t Ä‘á»™ng hiá»‡u quáº£ trong Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng thay Ä‘á»•i vÃ  cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t giá»¯a chuyá»ƒn Ä‘á»™ng thá»±c vÃ  nhiá»…u.

### Má»¥c TiÃªu ChÃ­nh

1. âœ… **PhÃ¢n vÃ¹ng ngÆ°á»i** (Person Segmentation) tá»« video/camera
2. âœ… **XÃ¡c Ä‘á»‹nh khu vá»±c cáº¥m** (Restricted Area Definition)
3. âœ… **PhÃ¡t hiá»‡n xÃ¢m nháº­p** (Intrusion Detection)
4. âœ… **Cáº£nh bÃ¡o tá»± Ä‘á»™ng** (Automated Alert System)
5. âœ… **Xá»­ lÃ½ Ã¡nh sÃ¡ng thay Ä‘á»•i** (Adaptive Lighting Handling)

---

## YÃªu Cáº§u Ká»¹ Thuáº­t

### 1. PhÃ¢n VÃ¹ng Chuyá»ƒn Äá»™ng (Motion Segmentation)
- **Frame Differencing**: PhÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng giá»¯a cÃ¡c frame liÃªn tiáº¿p
- **Background Subtraction**: TÃ¡ch foreground/background
- **Morphological Operations**: Loáº¡i bá» nhiá»…u, lÃ m má»‹n vÃ¹ng phÃ¡t hiá»‡n

### 2. Xá»­ LÃ½ Ãnh SÃ¡ng Thay Äá»•i
- **Adaptive Thresholding**: Äiá»u chá»‰nh threshold Ä‘á»™ng theo Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng
- **Histogram Equalization**: CÃ¢n báº±ng Ä‘á»™ tÆ°Æ¡ng pháº£n
- **Gamma Correction**: Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng

### 3. PhÃ¡t Hiá»‡n BiÃªn & VÃ¹ng
- **Edge Detection**: Sobel, Canny, hoáº·c Prewitt operators
- **Region Growing**: Má»Ÿ rá»™ng vÃ¹ng tá»« seed points
- **Contour Detection**: XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng viá»n Ä‘á»‘i tÆ°á»£ng

### 4. PhÃ¡t Hiá»‡n XÃ¢m Nháº­p
- **ROI (Region of Interest)**: Äá»‹nh nghÄ©a khu vá»±c cáº¥m
- **Overlap Detection**: Kiá»ƒm tra giao giá»¯a Ä‘á»‘i tÆ°á»£ng vÃ  ROI
- **Alert Triggering**: KÃ­ch hoáº¡t cáº£nh bÃ¡o khi phÃ¡t hiá»‡n xÃ¢m nháº­p

### 5. CÃ´ng Nghá»‡ Sá»­ Dá»¥ng
- **NgÃ´n ngá»¯**: Python (OpenCV) hoáº·c MATLAB
- **Libraries**: OpenCV, NumPy, scikit-image
- **Input**: Video files hoáº·c real-time camera
- **Output**: Video vá»›i bounding boxes + alert logs

---

## Cáº¥u TrÃºc Dá»± Ãn

### Folder Structure:

```
req-4-project/
â”œâ”€â”€ code/                           # Code implementation
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py                # Main application
â”‚   â”‚   â”œâ”€â”€ motion_detector.py     # Frame differencing & background subtraction
â”‚   â”‚   â”œâ”€â”€ adaptive_threshold.py  # Adaptive thresholding module
â”‚   â”‚   â”œâ”€â”€ edge_detector.py       # Edge detection (Sobel/Canny)
â”‚   â”‚   â”œâ”€â”€ region_grower.py       # Region growing algorithm
â”‚   â”‚   â”œâ”€â”€ intrusion_detector.py  # ROI & intrusion detection
â”‚   â”‚   â”œâ”€â”€ alert_system.py        # Alert logging and display
â”‚   â”‚   â””â”€â”€ utils.py               # Helper functions
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.yaml            # Configuration parameters
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ input/                 # Input videos
â”‚   â”‚   â”œâ”€â”€ output/                # Output videos & logs
â”‚   â”‚   â””â”€â”€ roi/                   # ROI definitions (JSON/XML)
â”‚   â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_motion.py
â”‚   â”‚   â”œâ”€â”€ test_threshold.py
â”‚   â”‚   â””â”€â”€ test_intrusion.py
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â””â”€â”€ README.md                  # Code documentation
â”‚
â”œâ”€â”€ documentation/                 # BÃ¡o cÃ¡o vÃ  tÃ i liá»‡u
â”‚   â”œâ”€â”€ 01-theory-foundation/
â”‚   â”‚   â”œâ”€â”€ 1.1-frame-differencing.md
â”‚   â”‚   â”œâ”€â”€ 1.2-adaptive-thresholding.md
â”‚   â”‚   â”œâ”€â”€ 1.3-edge-detection.md
â”‚   â”‚   â”œâ”€â”€ 1.4-region-growing.md
â”‚   â”‚   â”œâ”€â”€ 1.5-intrusion-detection.md
â”‚   â”‚   â””â”€â”€ references.md
â”‚   â”œâ”€â”€ 02-practical-implementation/
â”‚   â”‚   â”œâ”€â”€ 2.1-system-architecture.md
â”‚   â”‚   â”œâ”€â”€ 2.2-algorithm-design.md
â”‚   â”‚   â”œâ”€â”€ 2.3-implementation-details.md
â”‚   â”‚   â”œâ”€â”€ 2.4-parameter-tuning.md
â”‚   â”‚   â””â”€â”€ 2.5-user-guide.md
â”‚   â”œâ”€â”€ 03-evaluation/
â”‚   â”‚   â”œâ”€â”€ 3.1-test-scenarios.md
â”‚   â”‚   â”œâ”€â”€ 3.2-accuracy-analysis.md
â”‚   â”‚   â”œâ”€â”€ 3.3-lighting-conditions.md
â”‚   â”‚   â”œâ”€â”€ 3.4-performance-metrics.md
â”‚   â”‚   â””â”€â”€ 3.5-limitations.md
â”‚   â”œâ”€â”€ 04-deliverables/
â”‚   â”‚   â”œâ”€â”€ demo-video/
â”‚   â”‚   â”‚   â”œâ”€â”€ scenario-1-daylight.mp4
â”‚   â”‚   â”‚   â”œâ”€â”€ scenario-2-lowlight.mp4
â”‚   â”‚   â”‚   â””â”€â”€ scenario-3-night.mp4
â”‚   â”‚   â”œâ”€â”€ screenshots/
â”‚   â”‚   â””â”€â”€ report-final.pdf
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ implementation-guide/          # HÆ°á»›ng dáº«n triá»ƒn khai
â”‚   â”œâ”€â”€ 1-environment-setup.md
â”‚   â”œâ”€â”€ 2-data-preparation.md
â”‚   â”œâ”€â”€ 3-roi-definition.md
â”‚   â”œâ”€â”€ 4-configuration.md
â”‚   â”œâ”€â”€ 5-running-system.md
â”‚   â””â”€â”€ 6-troubleshooting.md
â”‚
â”œâ”€â”€ knowledge-base/                # Kiáº¿n thá»©c ná»n táº£ng
â”‚   â”œâ”€â”€ fundamentals/
â”‚   â”‚   â”œâ”€â”€ image-basics.md
â”‚   â”‚   â”œâ”€â”€ video-processing.md
â”‚   â”‚   â””â”€â”€ color-spaces.md
â”‚   â”œâ”€â”€ motion-detection/
â”‚   â”‚   â”œâ”€â”€ frame-differencing-theory.md
â”‚   â”‚   â”œâ”€â”€ background-subtraction-methods.md
â”‚   â”‚   â””â”€â”€ optical-flow.md
â”‚   â”œâ”€â”€ segmentation/
â”‚   â”‚   â”œâ”€â”€ thresholding-methods.md
â”‚   â”‚   â”œâ”€â”€ edge-based-segmentation.md
â”‚   â”‚   â””â”€â”€ region-based-segmentation.md
â”‚   â”œâ”€â”€ advanced-topics/
â”‚   â”‚   â”œâ”€â”€ adaptive-algorithms.md
â”‚   â”‚   â”œâ”€â”€ morphological-processing.md
â”‚   â”‚   â””â”€â”€ object-tracking.md
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                      # Project overview
```

---

## Chi Tiáº¿t CÃ¡c ThÃ nh Pháº§n

### ðŸ“‚ 1. Code Implementation (`code/`)

#### 1.1 Core Modules

##### `main.py`
```python
# Main application entry point
- Load configuration
- Initialize video source (file/camera)
- Load ROI definitions
- Run detection pipeline
- Display results with bounding boxes
- Save output video and logs
```

##### `motion_detector.py`
```python
# Motion detection module
- Frame differencing implementation
- Background subtraction (MOG2, KNN, GMG)
- Temporal filtering
- Morphological operations (erosion, dilation)
```

##### `adaptive_threshold.py`
```python
# Adaptive thresholding module
- Gaussian adaptive thresholding
- Mean adaptive thresholding
- Otsu's method
- Dynamic threshold adjustment
```

##### `edge_detector.py`
```python
# Edge detection module
- Sobel operator (horizontal, vertical, magnitude)
- Canny edge detection (with hysteresis)
- Prewitt operator
- Edge linking and refinement
```

##### `region_grower.py`
```python
# Region growing module
- Seed point selection
- Similarity criteria (intensity, gradient)
- Region expansion algorithm
- Connected component labeling
```

##### `intrusion_detector.py`
```python
# Intrusion detection module
- Load ROI polygons/rectangles
- Calculate overlap between detected objects and ROI
- Intrusion validation (time threshold, size filter)
- Generate alerts
```

##### `alert_system.py`
```python
# Alert system module
- Visual alerts (bounding boxes, text overlay)
- Audio alerts (beep sound)
- Log alerts to file (timestamp, location, screenshot)
- Optional: Send notifications (email, SMS)
```

#### 1.2 Configuration (`config/config.yaml`)

```yaml
# Video Input
video:
  source: "data/input/test_video.mp4"  # or 0 for webcam
  fps: 30

# Motion Detection
motion:
  method: "MOG2"  # MOG2, KNN, or frame_diff
  history: 500
  threshold: 16
  detect_shadows: true

# Adaptive Thresholding
threshold:
  method: "gaussian"  # gaussian or mean
  block_size: 11
  C: 2

# Edge Detection
edge:
  method: "canny"  # sobel or canny
  low_threshold: 50
  high_threshold: 150

# Morphological Operations
morphology:
  kernel_size: 5
  iterations: 2

# Intrusion Detection
intrusion:
  roi_file: "data/roi/restricted_area.json"
  overlap_threshold: 0.3  # 30% overlap
  time_threshold: 1.0  # 1 second
  min_object_area: 1000  # pixels

# Alert System
alert:
  visual: true
  audio: true
  log_file: "data/output/alerts.log"
  save_screenshots: true

# Output
output:
  save_video: true
  output_path: "data/output/result.mp4"
  show_realtime: true
```

#### 1.3 ROI Definition (`data/roi/restricted_area.json`)

```json
{
  "restricted_areas": [
    {
      "name": "Area 1",
      "type": "polygon",
      "points": [[100, 100], [400, 100], [400, 300], [100, 300]],
      "color": [255, 0, 0]
    },
    {
      "name": "Area 2",
      "type": "rectangle",
      "x": 500,
      "y": 200,
      "width": 200,
      "height": 150,
      "color": [0, 0, 255]
    }
  ]
}
```

#### 1.4 Dependencies (`requirements.txt`)

```
opencv-python>=4.8.0
numpy>=1.24.0
scikit-image>=0.21.0
matplotlib>=3.7.0
pyyaml>=6.0
pytest>=7.4.0
```

---

### ðŸ“š 2. Documentation (`documentation/`)

#### 2.1 Theory Foundation (`01-theory-foundation/`)

##### File: `1.1-frame-differencing.md`
**Ná»™i dung**:
- Äá»‹nh nghÄ©a vÃ  nguyÃªn lÃ½
- Thuáº­t toÃ¡n frame differencing cÆ¡ báº£n
- Temporal vs spatial differencing
- Æ¯u/nhÆ°á»£c Ä‘iá»ƒm
- á»¨ng dá»¥ng trong motion detection
- So sÃ¡nh vá»›i background subtraction

##### File: `1.2-adaptive-thresholding.md`
**Ná»™i dung**:
- Thresholding cÆ¡ báº£n vs adaptive
- Gaussian adaptive thresholding
- Mean adaptive thresholding
- Otsu's method
- Xá»­ lÃ½ Ã¡nh sÃ¡ng khÃ´ng Ä‘á»“ng Ä‘á»u
- Parameter tuning strategies

##### File: `1.3-edge-detection.md`
**Ná»™i dung**:
- Edge detection fundamentals
- Gradient operators (Sobel, Prewitt, Scharr)
- Canny edge detection (5 steps)
- Hysteresis thresholding
- Non-maximum suppression
- Edge linking techniques

##### File: `1.4-region-growing.md`
**Ná»™i dung**:
- Region growing algorithm
- Seed selection strategies
- Similarity criteria (intensity, color, texture)
- Region merging vÃ  splitting
- Connected components analysis
- 4-connectivity vs 8-connectivity

##### File: `1.5-intrusion-detection.md`
**Ná»™i dung**:
- ROI definition methods
- Overlap calculation (IoU, area percentage)
- Intrusion validation criteria
- False positive reduction
- Temporal consistency checks
- Multi-object tracking

##### File: `references.md`
**Ná»™i dung**:
- Academic papers
- Textbooks
- Online resources
- OpenCV documentation

#### 2.2 Practical Implementation (`02-practical-implementation/`)

##### File: `2.1-system-architecture.md`
**Ná»™i dung**:
```
System Architecture:

[Video Input]
    â†“
[Frame Preprocessing]
    â†“
[Motion Detection] â† [Background Model]
    â†“
[Adaptive Thresholding]
    â†“
[Edge Detection]
    â†“
[Region Growing] â†’ [Object Segmentation]
    â†“
[Intrusion Detection] â† [ROI Database]
    â†“
[Alert System] â†’ [Visual + Audio + Log]
    â†“
[Output Display/Save]
```

- Module interactions
- Data flow diagram
- Processing pipeline
- Real-time considerations

##### File: `2.2-algorithm-design.md`
**Ná»™i dung**:
- Detailed algorithm flowcharts
- Pseudocode for each module
- Decision trees for parameter selection
- Edge case handling

##### File: `2.3-implementation-details.md`
**Ná»™i dung**:
- Code structure explanation
- Key functions and classes
- Design patterns used
- Error handling strategies
- Performance optimizations

##### File: `2.4-parameter-tuning.md`
**Ná»™i dung**:
- Parameter sensitivity analysis
- Tuning guidelines for different scenarios
- Trade-offs (accuracy vs speed)
- Recommended values for various lighting conditions

##### File: `2.5-user-guide.md`
**Ná»™i dung**:
- Installation instructions
- Running the system step-by-step
- GUI/CLI usage
- Defining custom ROIs
- Interpreting results

#### 2.3 Evaluation (`03-evaluation/`)

##### File: `3.1-test-scenarios.md`
**Ná»™i dung**:
- Test case definitions
- Input video descriptions
- Expected outcomes
- Actual results

##### File: `3.2-accuracy-analysis.md`
**Ná»™i dung**:
- Performance metrics:
  - True Positive Rate (TPR)
  - False Positive Rate (FPR)
  - Precision, Recall, F1-score
  - IoU (Intersection over Union)
- Confusion matrix
- ROC curves

##### File: `3.3-lighting-conditions.md`
**Ná»™i dung**:
- **Daylight scenario**: High visibility, clear shadows
- **Low-light scenario**: Reduced contrast, noise increase
- **Night scenario**: Very low light, high noise
- Adaptive parameter adjustments for each
- Accuracy comparison table

##### File: `3.4-performance-metrics.md`
**Ná»™i dung**:
- Processing speed (FPS)
- Memory usage
- CPU/GPU utilization
- Latency analysis
- Scalability tests

##### File: `3.5-limitations.md`
**Ná»™i dung**:
- Current limitations
- Known issues
- False positives/negatives analysis
- Improvement suggestions
- Future work

#### 2.4 Deliverables (`04-deliverables/`)

##### Demo Videos:
- **scenario-1-daylight.mp4**: Outdoor, good lighting
- **scenario-2-lowlight.mp4**: Indoor, dim lighting
- **scenario-3-night.mp4**: Outdoor, night time

Each video should show:
- Original video feed
- Detected motion (highlighted)
- Bounding boxes around persons
- ROI overlay
- Alert triggers (visual + text)

##### Screenshots:
- System GUI/interface
- Alert notifications
- Parameter configuration panels
- Results visualization

##### Final Report (`report-final.pdf`):
- Complete documentation compiled
- All sections formatted professionally
- Includes:
  1. Cover page
  2. Table of contents
  3. Theory foundation
  4. Practical implementation
  5. Evaluation results
  6. Conclusion
  7. References
  8. Appendices (code listings, additional charts)

---

### ðŸ› ï¸ 3. Implementation Guide (`implementation-guide/`)

#### File: `1-environment-setup.md`

**Ná»™i dung**:

```markdown
# Environment Setup

## 1. System Requirements
- **OS**: Windows 10/11, Ubuntu 20.04+, or macOS 11+
- **Python**: 3.8 or higher
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 2GB for code + data
- **Camera**: Optional, for real-time testing

## 2. Install Python
```bash
# Check Python version
python --version  # or python3 --version

# If not installed, download from python.org
```

## 3. Create Virtual Environment
```bash
# Navigate to project directory
cd req-4-project/code

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Linux/Mac:
source venv/bin/activate
```

## 4. Install Dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## 5. Verify Installation
```bash
python -c "import cv2; print(cv2.__version__)"
python -c "import numpy; print(numpy.__version__)"
```

## 6. IDE Setup (Optional)
- **VS Code**: Install Python extension
- **PyCharm**: Configure Python interpreter
- **Jupyter**: For experimentation
  ```bash
  pip install jupyter
  jupyter notebook
  ```

## 7. GPU Support (Optional)
For faster processing with CUDA:
```bash
pip install opencv-contrib-python-headless
# Follow CUDA installation guide for your system
```
```

#### File: `2-data-preparation.md`

**Ná»™i dung**:

```markdown
# Data Preparation

## 1. Input Video Requirements
- **Format**: MP4, AVI, MOV, or any OpenCV-supported format
- **Resolution**: 640x480 minimum, 1920x1080 recommended
- **FPS**: 25-30 FPS
- **Duration**: 30 seconds to 5 minutes for testing

## 2. Obtaining Test Videos

### Option A: Download Sample Videos
```bash
# Create data directories
mkdir -p data/input
mkdir -p data/output

# Download sample surveillance videos
# Example sources:
# - Pexels.com (free stock videos)
# - YouTube (Creative Commons)
# - VIRAT Video Dataset (surveillance)
```

### Option B: Record Your Own
- Use smartphone or webcam
- Ensure good coverage of test area
- Include various scenarios:
  - Person entering restricted area
  - Person walking near (but not entering) restricted area
  - No persons present
  - Multiple persons

### Option C: Use Real-time Camera
- Connect USB webcam or IP camera
- Set `source: 0` in config.yaml for default webcam
- Set `source: "rtsp://..."` for IP camera

## 3. Video Preprocessing (Optional)
If videos need adjustment:

```python
import cv2

# Resize video
def resize_video(input_path, output_path, width=1280, height=720):
    cap = cv2.VideoCapture(input_path)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fps = cap.get(cv2.CAP_PROP_FPS)
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        resized = cv2.resize(frame, (width, height))
        out.write(resized)

    cap.release()
    out.release()
```

## 4. Data Organization
```
data/
â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ test_video_1.mp4
â”‚   â”œâ”€â”€ test_video_2.mp4
â”‚   â””â”€â”€ test_video_3.mp4
â”œâ”€â”€ output/
â”‚   â””â”€â”€ (results will be saved here)
â””â”€â”€ roi/
    â”œâ”€â”€ restricted_area.json
    â””â”€â”€ (ROI definitions)
```

## 5. Quality Checks
Before running:
- [ ] Videos play correctly in media player
- [ ] Resolution is clear enough to see persons
- [ ] Lighting conditions are representative
- [ ] File paths are correct in config.yaml
```

#### File: `3-roi-definition.md`

**Ná»™i dung**:

```markdown
# ROI (Region of Interest) Definition

## Overview
ROI defines the restricted area(s) where intrusion detection is active.

## Method 1: Manual JSON Editing

Edit `data/roi/restricted_area.json`:

```json
{
  "restricted_areas": [
    {
      "name": "Main Entrance",
      "type": "polygon",
      "points": [[100, 100], [400, 100], [400, 300], [100, 300]],
      "color": [255, 0, 0]
    }
  ]
}
```

### Polygon Points:
- Define vertices in clockwise or counter-clockwise order
- Coordinates are (x, y) in pixels
- Origin (0, 0) is top-left corner

### Rectangle:
```json
{
  "name": "Loading Dock",
  "type": "rectangle",
  "x": 500,
  "y": 200,
  "width": 200,
  "height": 150,
  "color": [0, 0, 255]
}
```

## Method 2: Interactive ROI Selection Tool

Create `tools/roi_selector.py`:

```python
import cv2
import json

class ROISelector:
    def __init__(self, video_path):
        self.video_path = video_path
        self.points = []
        self.rois = []

    def mouse_callback(self, event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            self.points.append([x, y])
            print(f"Point added: ({x}, {y})")
        elif event == cv2.EVENT_RBUTTONDOWN:
            if len(self.points) >= 3:
                roi = {
                    "name": f"Area {len(self.rois) + 1}",
                    "type": "polygon",
                    "points": self.points.copy(),
                    "color": [255, 0, 0]
                }
                self.rois.append(roi)
                print(f"ROI saved: {len(self.points)} points")
                self.points = []

    def run(self):
        cap = cv2.VideoCapture(self.video_path)
        ret, frame = cap.read()
        cap.release()

        if not ret:
            print("Error: Cannot read video")
            return

        cv2.namedWindow("ROI Selector")
        cv2.setMouseCallback("ROI Selector", self.mouse_callback)

        print("Instructions:")
        print("- Left click: Add point")
        print("- Right click: Finish current ROI")
        print("- Press 's': Save and exit")
        print("- Press 'c': Clear current points")
        print("- Press 'q': Quit without saving")

        while True:
            display = frame.copy()

            # Draw current points
            for pt in self.points:
                cv2.circle(display, tuple(pt), 5, (0, 255, 0), -1)

            # Draw lines between points
            if len(self.points) > 1:
                for i in range(len(self.points) - 1):
                    cv2.line(display, tuple(self.points[i]),
                            tuple(self.points[i+1]), (0, 255, 0), 2)

            # Draw saved ROIs
            for roi in self.rois:
                pts = roi["points"]
                for i in range(len(pts)):
                    cv2.line(display, tuple(pts[i]),
                            tuple(pts[(i+1) % len(pts)]), tuple(roi["color"]), 2)

            cv2.imshow("ROI Selector", display)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('s'):
                self.save_rois()
                break
            elif key == ord('c'):
                self.points = []
                print("Points cleared")
            elif key == ord('q'):
                break

        cv2.destroyAllWindows()

    def save_rois(self):
        output = {"restricted_areas": self.rois}
        with open("data/roi/restricted_area.json", "w") as f:
            json.dump(output, f, indent=2)
        print(f"Saved {len(self.rois)} ROI(s) to restricted_area.json")

if __name__ == "__main__":
    selector = ROISelector("data/input/test_video.mp4")
    selector.run()
```

### Usage:
```bash
python tools/roi_selector.py
```

## Method 3: Use First Frame
For quick testing, use entire frame or simple coordinates:

```json
{
  "restricted_areas": [
    {
      "name": "Full Frame",
      "type": "rectangle",
      "x": 0,
      "y": 0,
      "width": 1280,
      "height": 720,
      "color": [255, 0, 0]
    }
  ]
}
```

## Tips
- Test ROI on a static frame first
- Use contrasting colors for visibility
- Avoid overly complex polygons (3-6 points ideal)
- Multiple smaller ROIs > one large complex ROI
```

#### File: `4-configuration.md`

**Ná»™i dung**:

```markdown
# Configuration Guide

## Configuration File: `config/config.yaml`

### Video Input
```yaml
video:
  source: "data/input/test_video.mp4"  # Path or camera index
  fps: 30                              # Frame rate (if reading from file)
```

**Options:**
- File path: `"path/to/video.mp4"`
- Webcam: `0` (default camera) or `1, 2, ...` for additional cameras
- IP camera: `"rtsp://username:password@ip:port/stream"`

### Motion Detection
```yaml
motion:
  method: "MOG2"        # Options: "MOG2", "KNN", "frame_diff"
  history: 500          # Number of frames for background learning
  threshold: 16         # Sensitivity (lower = more sensitive)
  detect_shadows: true  # Detect and mark shadows
```

**Tuning:**
- **Daylight**: `threshold: 16-25`, `history: 500`
- **Low-light**: `threshold: 10-15`, `history: 300`
- **Night**: `threshold: 8-12`, `history: 200`

### Adaptive Thresholding
```yaml
threshold:
  method: "gaussian"    # Options: "gaussian", "mean"
  block_size: 11        # Neighborhood size (must be odd)
  C: 2                  # Constant subtracted from mean
```

**Tuning:**
- **High contrast**: `block_size: 7-11`, `C: 2-5`
- **Low contrast**: `block_size: 15-21`, `C: 1-3`
- **Noisy**: `block_size: 15-25`, `C: 5-10`

### Edge Detection
```yaml
edge:
  method: "canny"           # Options: "canny", "sobel"
  low_threshold: 50         # Canny lower threshold
  high_threshold: 150       # Canny upper threshold
```

**Tuning:**
- **Sharp edges only**: `low: 100`, `high: 200`
- **More edges**: `low: 30`, `high: 100`
- **Sobel**: Use magnitude threshold instead

### Morphological Operations
```yaml
morphology:
  kernel_size: 5        # Size of structuring element
  iterations: 2         # Number of times to apply
```

**Purpose:**
- Remove noise (erosion â†’ dilation)
- Fill holes (dilation â†’ erosion)
- Smooth boundaries

### Intrusion Detection
```yaml
intrusion:
  roi_file: "data/roi/restricted_area.json"
  overlap_threshold: 0.3   # Min overlap ratio to trigger (30%)
  time_threshold: 1.0      # Seconds object must be in ROI
  min_object_area: 1000    # Min pixel area to consider
```

**Tuning:**
- **Strict detection**: `overlap: 0.5`, `time: 2.0`
- **Lenient detection**: `overlap: 0.2`, `time: 0.5`
- **Filter small objects**: Increase `min_object_area`

### Alert System
```yaml
alert:
  visual: true                          # Show on video
  audio: true                           # Play sound
  log_file: "data/output/alerts.log"   # Log file path
  save_screenshots: true                # Save frame on alert
```

### Output
```yaml
output:
  save_video: true                      # Save output video
  output_path: "data/output/result.mp4"
  show_realtime: true                   # Display while processing
```

## Quick Presets

### Preset 1: Outdoor Daylight
```yaml
motion:
  threshold: 20
threshold:
  block_size: 11
  C: 2
edge:
  low_threshold: 50
  high_threshold: 150
```

### Preset 2: Indoor Low-Light
```yaml
motion:
  threshold: 12
threshold:
  block_size: 15
  C: 3
edge:
  low_threshold: 30
  high_threshold: 100
```

### Preset 3: Night
```yaml
motion:
  threshold: 10
threshold:
  block_size: 21
  C: 5
edge:
  low_threshold: 20
  high_threshold: 80
```
```

#### File: `5-running-system.md`

**Ná»™i dung**:

```markdown
# Running the System

## Step-by-Step Execution

### 1. Activate Environment
```bash
cd req-4-project/code
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows
```

### 2. Verify Setup
```bash
# Check files
ls data/input/           # Input videos present?
ls data/roi/             # ROI file present?
cat config/config.yaml   # Config correct?
```

### 3. Run Main Program
```bash
python src/main.py
```

### 4. Command-Line Arguments (Optional)

```bash
# Use custom config
python src/main.py --config custom_config.yaml

# Override video source
python src/main.py --source data/input/another_video.mp4

# Use webcam
python src/main.py --source 0

# Skip display (headless)
python src/main.py --no-display

# Save output only
python src/main.py --output-only
```

### 5. Expected Output

**Console:**
```
[INFO] Loading configuration...
[INFO] Initializing video source...
[INFO] Video: 1280x720 @ 30 FPS
[INFO] Loading ROI definitions...
[INFO] ROI: 2 restricted areas loaded
[INFO] Starting detection pipeline...
[INFO] Processing frame 1/900...
[ALERT] Intrusion detected at 00:05 in Area 1!
[INFO] Processing frame 2/900...
...
[INFO] Processing complete. Saved to data/output/result.mp4
[INFO] Total alerts: 3
[INFO] Alert log: data/output/alerts.log
```

**Display Window:**
- Original video with overlays:
  - Red polygons: ROI areas
  - Green boxes: Detected persons (no intrusion)
  - Red boxes: Persons in restricted area (intrusion)
  - Text: "ALERT - INTRUSION DETECTED"
  - Frame counter, FPS

### 6. Reviewing Results

#### Output Video:
```bash
# Open with default player
open data/output/result.mp4  # Mac
xdg-open data/output/result.mp4  # Linux
start data/output/result.mp4  # Windows
```

#### Alert Log:
```bash
cat data/output/alerts.log
```

Example log:
```
2025-01-06 14:32:15 | ALERT | Area 1 | Intrusion detected | Frame 150 | Screenshot: alert_001.png
2025-01-06 14:32:18 | ALERT | Area 1 | Intrusion detected | Frame 240 | Screenshot: alert_002.png
2025-01-06 14:33:02 | ALERT | Area 2 | Intrusion detected | Frame 890 | Screenshot: alert_003.png
```

#### Screenshots:
```bash
ls data/output/screenshots/
# alert_001.png, alert_002.png, ...
```

## Interactive Mode

For real-time tuning, use interactive mode:

```bash
python src/main.py --interactive
```

**Controls:**
- `p`: Pause/resume
- `s`: Save current frame
- `r`: Reset background model
- `+/-`: Adjust threshold
- `q`: Quit

## Batch Processing

Process multiple videos:

```bash
python src/batch_process.py --input-dir data/input/ --output-dir data/output/
```

## Troubleshooting During Run

| Issue | Solution |
|-------|----------|
| No video display | Check `show_realtime: true` in config |
| Too many false alerts | Increase `overlap_threshold` or `min_object_area` |
| Missing real intrusions | Decrease `motion.threshold`, increase sensitivity |
| Slow processing | Reduce resolution, disable `save_video` |
| Camera not opening | Check source index, permissions, cable |

## Performance Monitoring

```bash
# With FPS counter
python src/main.py --show-fps

# With resource monitoring
python src/main.py --profile
```

## Stopping the System

- Press `q` in display window
- `Ctrl+C` in terminal (graceful shutdown)
- Kills background processes automatically
```

#### File: `6-troubleshooting.md`

**Ná»™i dung**:

```markdown
# Troubleshooting Guide

## Installation Issues

### Issue: `pip install` fails
**Symptoms:**
```
ERROR: Could not find a version that satisfies the requirement opencv-python
```

**Solutions:**
1. Update pip: `pip install --upgrade pip`
2. Check Python version: `python --version` (need 3.8+)
3. Try: `pip install opencv-python-headless`
4. Install from wheel file

### Issue: Import errors
**Symptoms:**
```
ModuleNotFoundError: No module named 'cv2'
```

**Solutions:**
1. Ensure virtual environment is activated
2. Reinstall: `pip uninstall opencv-python && pip install opencv-python`
3. Check installation: `pip list | grep opencv`

## Runtime Issues

### Issue: Video not opening
**Symptoms:**
```
[ERROR] Cannot open video source
```

**Solutions:**
1. Check file path is correct
2. Verify video file is not corrupted (play in VLC)
3. For webcam: Try different indices (0, 1, 2)
4. For webcam: Check permissions (especially macOS)
5. Install additional codecs: `pip install opencv-contrib-python`

### Issue: ROI file not found
**Symptoms:**
```
FileNotFoundError: data/roi/restricted_area.json
```

**Solutions:**
1. Create directory: `mkdir -p data/roi`
2. Create minimal ROI file (see `3-roi-definition.md`)
3. Check `roi_file` path in `config.yaml`

### Issue: No motion detected
**Symptoms:**
- Video plays but no bounding boxes appear
- No alerts even when person clearly visible

**Solutions:**
1. Lower `motion.threshold` in config (try 10)
2. Check background subtraction method (try "MOG2" â†’ "frame_diff")
3. Verify `min_object_area` not too high
4. Print debug info: Add `--debug` flag

### Issue: Too many false alerts
**Symptoms:**
- Constant alerts with no persons
- Shadows/lighting triggering alerts

**Solutions:**
1. Increase `overlap_threshold` (0.3 â†’ 0.5)
2. Increase `time_threshold` (1.0 â†’ 2.0)
3. Enable shadow detection: `detect_shadows: true`
4. Increase `min_object_area` to filter noise
5. Adjust `motion.threshold` higher (16 â†’ 25)

### Issue: Slow processing
**Symptoms:**
- Low FPS (<5 FPS)
- High CPU usage

**Solutions:**
1. Reduce video resolution:
   ```python
   frame = cv2.resize(frame, (640, 360))
   ```
2. Skip frames:
   ```python
   if frame_count % 2 == 0:  # Process every 2nd frame
   ```
3. Disable real-time display: `show_realtime: false`
4. Use GPU acceleration (requires CUDA)
5. Simplify ROI (fewer points)

### Issue: Out of memory
**Symptoms:**
```
MemoryError: Unable to allocate array
```

**Solutions:**
1. Process shorter video segments
2. Reduce history: `history: 500` â†’ `200`
3. Release unused variables
4. Use `frame_diff` instead of `MOG2/KNN`

## Detection Quality Issues

### Issue: Edges not detected properly
**Symptoms:**
- Incomplete object boundaries
- Missing edges in low light

**Solutions:**
1. Adjust Canny thresholds:
   - Lower both thresholds for more edges
   - Maintain 1:2 or 1:3 ratio (low:high)
2. Try Sobel instead of Canny
3. Apply Gaussian blur before edge detection
4. Increase contrast with histogram equalization

### Issue: Segmentation errors
**Symptoms:**
- Person split into multiple regions
- Background included in person region

**Solutions:**
1. Adjust morphology:
   - Increase `kernel_size` (5 â†’ 7)
   - Increase `iterations` (2 â†’ 3)
2. Use closing operation to fill holes
3. Apply median filter to reduce noise
4. Tune region growing similarity threshold

### Issue: Lighting changes cause issues
**Symptoms:**
- Sudden lighting change triggers false alerts
- System fails in shadows

**Solutions:**
1. Use adaptive thresholding (already in pipeline)
2. Increase `history` for background model (500 â†’ 1000)
3. Apply gamma correction:
   ```python
   frame = np.power(frame/255.0, 0.7) * 255
   ```
4. Use histogram equalization per frame
5. Consider CLAHE (Contrast Limited AHE)

## Configuration Issues

### Issue: YAML syntax error
**Symptoms:**
```
yaml.scanner.ScannerError: mapping values are not allowed here
```

**Solutions:**
1. Check indentation (use spaces, not tabs)
2. Quote string values: `"value"`
3. Validate YAML online: yamllint.com

### Issue: JSON ROI syntax error
**Symptoms:**
```
json.decoder.JSONDecodeError: Expecting property name
```

**Solutions:**
1. Validate JSON online: jsonlint.com
2. Check commas, brackets, quotes
3. Use ROI selector tool instead of manual editing

## Platform-Specific Issues

### macOS:
- **Camera permission**: System Preferences â†’ Security & Privacy â†’ Camera
- **File permissions**: Check `chmod` on directories

### Windows:
- **Path separators**: Use `/` or `\\` (not single `\`)
- **Antivirus**: May block camera access, whitelist Python

### Linux:
- **Camera device**: May be `/dev/video0`, `/dev/video1`
- **Permissions**: Add user to `video` group:
  ```bash
  sudo usermod -a -G video $USER
  ```

## Getting Help

### Enable Debug Mode
```bash
python src/main.py --debug
```
Shows detailed logs for each processing step.

### Generate Debug Report
```bash
python src/debug_report.py
```
Outputs system info, config, sample frames.

### Check Logs
```bash
tail -f data/output/alerts.log
```

### Test Individual Modules
```bash
# Test motion detection only
python tests/test_motion.py

# Test threshold only
python tests/test_threshold.py
```

### Common Commands for Diagnosis
```bash
# Check OpenCV build info
python -c "import cv2; print(cv2.getBuildInformation())"

# Test video file
python -c "import cv2; cap=cv2.VideoCapture('video.mp4'); print(cap.isOpened())"

# Test camera
python -c "import cv2; cap=cv2.VideoCapture(0); print(cap.isOpened())"
```

## Still Stuck?

1. Check project README.md
2. Review example outputs in `documentation/04-deliverables/`
3. Compare your config with preset configurations
4. Simplify: Start with minimal config, add complexity gradually
5. Test with different input video (ensure input is valid)
```

---

### ðŸ§  4. Knowledge Base (`knowledge-base/`)

#### 4.1 Fundamentals (`fundamentals/`)

##### File: `image-basics.md`
**Ná»™i dung**:
- Digital image representation (matrix, pixels, channels)
- Color spaces (RGB, BGR, Grayscale, HSV)
- Image resolution and dimensions
- Pixel intensity values (0-255 for 8-bit)
- Image formats (PNG, JPEG, BMP)
- Reading/writing images with OpenCV
- Basic operations (crop, resize, flip, rotate)

##### File: `video-processing.md`
**Ná»™i dung**:
- Video as sequence of frames
- Frame rate (FPS) vÃ  temporal resolution
- Video codecs and containers
- Reading frames with VideoCapture
- Writing videos with VideoWriter
- Frame extraction techniques
- Temporal vs spatial information

##### File: `color-spaces.md`
**Ná»™i dung**:
- RGB: Standard color model
- BGR: OpenCV default
- Grayscale: Single channel intensity
- HSV: Hue, Saturation, Value (better for segmentation)
- YCbCr: Luminance and chrominance
- Color space conversion vá»›i `cv2.cvtColor()`
- When to use which color space

#### 4.2 Motion Detection (`motion-detection/`)

##### File: `frame-differencing-theory.md`

**Ná»™i dung**:

```markdown
# Frame Differencing Theory

## Definition
Frame differencing lÃ  ká»¹ thuáº­t phÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng báº±ng cÃ¡ch so sÃ¡nh cÃ¡c frame liÃªn tiáº¿p trong video.

## Basic Algorithm

### 1. Consecutive Frame Differencing
```
D(t) = |F(t) - F(t-1)|
```
- F(t): Current frame
- F(t-1): Previous frame
- D(t): Difference image

### 2. Thresholding
```
Binary(t) = {
  255 if D(t) > threshold
  0   otherwise
}
```

### 3. Steps:
1. Read frame F(t)
2. Convert to grayscale
3. Compute difference with previous frame
4. Apply threshold
5. Morphological operations (optional)
6. Find contours
7. Draw bounding boxes

## Variants

### A. Two-Frame Difference
```python
diff = cv2.absdiff(frame_t, frame_t_1)
```
**Pros**: Simple, fast
**Cons**: Sensitive to noise

### B. Three-Frame Difference
```python
diff1 = cv2.absdiff(frame_t, frame_t_1)
diff2 = cv2.absdiff(frame_t_1, frame_t_2)
motion = cv2.bitwise_and(diff1, diff2)
```
**Pros**: More robust
**Cons**: Slower, may miss fast motion

### C. Weighted Difference
```python
diff = cv2.absdiff(frame_t, alpha*frame_t_1 + (1-alpha)*frame_t_2)
```
**Pros**: Temporal smoothing
**Cons**: More complex

## Threshold Selection

### Fixed Threshold:
```python
threshold = 25
_, binary = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)
```

### Adaptive Threshold:
```python
binary = cv2.adaptiveThreshold(diff, 255,
    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY, 11, 2)
```

### Otsu's Method:
```python
_, binary = cv2.threshold(diff, 0, 255,
    cv2.THRESH_BINARY + cv2.THRESH_OTSU)
```

## Morphological Post-Processing

```python
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))

# Remove noise
opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)

# Fill holes
closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)

# Smooth boundaries
dilated = cv2.dilate(closed, kernel, iterations=2)
```

## Advantages
âœ… Simple to implement
âœ… Fast computation
âœ… No training required
âœ… Works well for static cameras

## Disadvantages
âŒ Sensitive to noise
âŒ Affected by illumination changes
âŒ Camera jitter causes false detections
âŒ Moving objects only (not stationary objects)
âŒ Ghost effect (holes in moving objects)

## Improvements

### 1. Gaussian Blur
```python
frame = cv2.GaussianBlur(frame, (5, 5), 0)
```
Reduces noise before differencing.

### 2. Background Subtraction
Instead of F(t-1), use learned background model.

### 3. Multi-Scale
Compute differences at multiple resolutions.

### 4. Temporal Median
Use median of last N frames instead of single previous frame.

## Applications
- Motion detection in surveillance
- Activity recognition
- Change detection
- Video compression (motion estimation)
- Sports analysis

## Comparison with Background Subtraction

| Feature | Frame Diff | Background Subtraction |
|---------|------------|------------------------|
| **Complexity** | Low | Medium-High |
| **Speed** | Fast | Medium |
| **Accuracy** | Medium | High |
| **Lighting** | Sensitive | Adaptive |
| **Setup** | None | Learning period |
| **Stationary** | âŒ | âœ… |

## Example Code

```python
import cv2
import numpy as np

def frame_difference(video_path):
    cap = cv2.VideoCapture(video_path)
    ret, frame1 = cap.read()
    ret, frame2 = cap.read()

    while cap.isOpened():
        # Convert to grayscale
        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)

        # Compute difference
        diff = cv2.absdiff(gray1, gray2)

        # Apply Gaussian blur
        diff = cv2.GaussianBlur(diff, (5, 5), 0)

        # Threshold
        _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)

        # Morphology
        kernel = np.ones((5, 5), np.uint8)
        thresh = cv2.dilate(thresh, kernel, iterations=2)

        # Find contours
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,
                                       cv2.CHAIN_APPROX_SIMPLE)

        # Draw bounding boxes
        for contour in contours:
            if cv2.contourArea(contour) > 1000:  # Filter small areas
                x, y, w, h = cv2.boundingRect(contour)
                cv2.rectangle(frame2, (x, y), (x+w, y+h), (0, 255, 0), 2)

        # Display
        cv2.imshow("Frame Difference", frame2)
        cv2.imshow("Threshold", thresh)

        # Update frames
        frame1 = frame2
        ret, frame2 = cap.read()

        if not ret or cv2.waitKey(30) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
```

## Further Reading
- "Background and Foreground Modeling" (Piccardi, 2004)
- "Adaptive Background Mixture Models" (Stauffer & Grimson, 1999)
- OpenCV Documentation: Background Subtraction
```

##### File: `background-subtraction-methods.md`

**Ná»™i dung**:
- Difference from frame differencing
- Background modeling concepts
- MOG (Mixture of Gaussians)
- MOG2 (Improved MOG)
- KNN (K-Nearest Neighbors)
- GMG (Geometric Multigrid)
- Comparison of methods
- Learning rate and history
- Shadow detection
- OpenCV implementation vá»›i `cv2.createBackgroundSubtractor*()`

##### File: `optical-flow.md`

**Ná»™i dung**:
- Optical flow definition (motion vectors)
- Dense vs sparse optical flow
- Lucas-Kanade method
- Farneback method
- Applications in motion tracking
- Visualization techniques
- Comparison with frame differencing

#### 4.3 Segmentation (`segmentation/`)

##### File: `thresholding-methods.md`

**Ná»™i dung**:

```markdown
# Thresholding Methods

## Overview
Thresholding converts grayscale image â†’ binary image by comparing pixel intensities to threshold value(s).

## 1. Global Thresholding

### Basic Thresholding
```
Binary(x,y) = {
  maxval  if I(x,y) > threshold
  0       otherwise
}
```

### OpenCV Types:
```python
_, binary = cv2.threshold(gray, thresh, maxval, cv2.THRESH_BINARY)
```

- `THRESH_BINARY`: value = maxval if > thresh, else 0
- `THRESH_BINARY_INV`: Inverse of binary
- `THRESH_TRUNC`: value = thresh if > thresh, else unchanged
- `THRESH_TOZERO`: value = unchanged if > thresh, else 0
- `THRESH_TOZERO_INV`: Inverse of tozero

### Otsu's Method (Automatic Threshold Selection)
```python
_, binary = cv2.threshold(gray, 0, 255,
    cv2.THRESH_BINARY + cv2.THRESH_OTSU)
```

**How it works:**
- Computes histogram
- Tries all possible thresholds
- Selects threshold that minimizes intra-class variance
- Optimal for bimodal histograms

## 2. Adaptive Thresholding

### Why Adaptive?
- **Problem**: Global threshold fails with non-uniform lighting
- **Solution**: Calculate threshold for small regions

### Adaptive Mean
```python
binary = cv2.adaptiveThreshold(gray, 255,
    cv2.ADAPTIVE_THRESH_MEAN_C,
    cv2.THRESH_BINARY, block_size, C)
```

**Threshold** = mean of (block_size Ã— block_size) neighborhood - C

### Adaptive Gaussian
```python
binary = cv2.adaptiveThreshold(gray, 255,
    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY, block_size, C)
```

**Threshold** = Gaussian-weighted mean - C

### Parameters:
- **block_size**: Neighborhood size (must be odd, e.g., 11, 15, 21)
  - Smaller â†’ more local adaptation
  - Larger â†’ smoother, less noise
- **C**: Constant subtracted from mean (fine-tuning)
  - Positive C â†’ lower threshold â†’ more foreground
  - Negative C â†’ higher threshold â†’ less foreground

## 3. Multi-Level Thresholding

For multiple regions:
```python
_, level1 = cv2.threshold(gray, thresh1, 255, cv2.THRESH_BINARY)
_, level2 = cv2.threshold(gray, thresh2, 255, cv2.THRESH_BINARY)
multi_level = level1 - level2  # Pixels between thresh1 and thresh2
```

## 4. Color-Based Thresholding

In HSV space:
```python
hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
lower = np.array([hue_min, sat_min, val_min])
upper = np.array([hue_max, sat_max, val_max])
mask = cv2.inRange(hsv, lower, upper)
```

**Use case**: Segment specific colors (e.g., red objects)

## Comparison

| Method | Best For | Pros | Cons |
|--------|----------|------|------|
| **Global** | Uniform lighting | Simple, fast | Fails with gradients |
| **Otsu** | Bimodal histogram | Automatic | Not adaptive |
| **Adaptive Mean** | Variable lighting | Handles gradients | Slower |
| **Adaptive Gaussian** | Smooth gradients | Best quality | Slowest |
| **Color** | Colored objects | Robust to lighting | Needs color tuning |

## Tips for Intrusion Detection

1. **Pre-processing:**
   - Gaussian blur to reduce noise
   - Histogram equalization if too dark/bright

2. **Choose method:**
   - **Daylight (uniform)**: Otsu
   - **Indoor (variable light)**: Adaptive Gaussian
   - **Night (low contrast)**: Adaptive Mean with larger block_size

3. **Post-processing:**
   - Morphological opening: Remove noise
   - Morphological closing: Fill holes

4. **Parameter tuning:**
   - Start with block_size=11, C=2
   - Increase block_size if too noisy
   - Adjust C if too much/little foreground

## Example for Person Detection

```python
def adaptive_person_threshold(frame):
    # Convert to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian blur
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Adaptive thresholding
    binary = cv2.adaptiveThreshold(blurred, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,  # Inverse: person = white
        block_size=15,
        C=3)

    # Morphological operations
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    return binary
```

## Further Reading
- Otsu's original paper (1979)
- "Adaptive Thresholding for the DigitalDesk" (Wellner, 1993)
- Digital Image Processing (Gonzalez & Woods) - Chapter 10
```

##### File: `edge-based-segmentation.md`
**Ná»™i dung**:
- Edge detection fundamentals
- Gradient-based methods (Sobel, Prewitt, Scharr)
- Canny edge detection (detailed 5-step algorithm)
- Laplacian of Gaussian (LoG)
- Edge linking vÃ  boundary tracing
- Integration with region growing
- Applications in object segmentation

##### File: `region-based-segmentation.md`
**Ná»™i dung**:
- Region growing algorithm
- Seeded region growing
- Similarity predicates (intensity, color, texture)
- Region merging and splitting
- Watershed algorithm
- Connected components analysis
- Application to person segmentation

#### 4.4 Advanced Topics (`advanced-topics/`)

##### File: `adaptive-algorithms.md`
**Ná»™i dung**:
- Adaptive thresholding in depth
- Adaptive background modeling
- Learning rate adjustment
- Handling gradual lighting changes
- Sudden change detection
- Parameter self-tuning strategies

##### File: `morphological-processing.md`
**Ná»™i dung**:
- Structuring elements
- Erosion and dilation
- Opening and closing
- Morphological gradient
- Top-hat and black-hat transforms
- Application to noise removal and hole filling
- Choosing kernel size and shape

##### File: `object-tracking.md`
**Ná»™i dung**:
- Tracking vs detection
- Centroid tracking
- Kalman filtering
- Mean-shift and CAMShift
- Optical flow tracking
- Multi-object tracking (MOT)
- Handling occlusions
- Track association vÃ  ID assignment

---

### ðŸ“‹ 5. Main README (`README.md`)

**Ná»™i dung**:

```markdown
# REQ-4 Project: Person Segmentation & Intrusion Detection

## Overview
This project implements an intelligent surveillance system that detects persons entering restricted areas using computer vision techniques. The system works in various lighting conditions and provides real-time alerts.

## Project Structure

```
req-4-project/
â”œâ”€â”€ code/                      # Implementation
â”œâ”€â”€ documentation/             # Reports and theory
â”œâ”€â”€ implementation-guide/      # Setup and usage instructions
â”œâ”€â”€ knowledge-base/           # Learning resources
â””â”€â”€ README.md                 # This file
```

## Quick Start

### 1. Setup Environment
```bash
cd code
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 2. Prepare Data
- Place test videos in `code/data/input/`
- Define ROI in `code/data/roi/restricted_area.json`
  (Use `python tools/roi_selector.py` for interactive selection)

### 3. Configure
Edit `code/config/config.yaml` to match your scenario.

### 4. Run
```bash
cd code
python src/main.py
```

## Features
âœ… Motion-based person detection (frame differencing + background subtraction)
âœ… Adaptive thresholding for variable lighting
âœ… Edge detection and region growing for segmentation
âœ… Custom ROI definition (polygons/rectangles)
âœ… Real-time intrusion alerts (visual + audio + logging)
âœ… Output video with bounding boxes and overlays
âœ… Works in daylight, low-light, and night conditions

## Technical Stack
- **Language**: Python 3.8+
- **Libraries**: OpenCV, NumPy, scikit-image
- **Algorithms**:
  - Motion Detection: MOG2, KNN, Frame Differencing
  - Segmentation: Adaptive Thresholding, Canny Edge Detection
  - Region Growing with seed-based expansion
  - Intrusion Detection: IoU-based overlap calculation

## Documentation

### For Implementation:
1. **implementation-guide/**: Step-by-step setup and usage
2. **code/README.md**: Code structure and module details

### For Understanding:
1. **knowledge-base/**: Theory and concepts
2. **documentation/01-theory-foundation/**: Detailed explanations

### For Evaluation:
1. **documentation/03-evaluation/**: Test results and analysis
2. **documentation/04-deliverables/**: Demo videos and reports

## Results

### Performance Metrics:
- **Processing Speed**: ~25-30 FPS (1280x720)
- **Detection Accuracy**: 92% (daylight), 85% (low-light), 78% (night)
- **False Positive Rate**: <5%
- **Memory Usage**: ~200MB

### Test Scenarios:
1. **Daylight**: Clear visibility, high accuracy
2. **Low-light**: Moderate visibility, adaptive threshold performs well
3. **Night**: Low visibility, challenges with dark clothing

## Limitations
- Requires relatively static camera
- Struggles with very crowded scenes
- False positives during sudden lighting changes (lightning, car headlights)
- Cannot distinguish between authorized/unauthorized persons (no face recognition)

## Future Improvements
- Deep learning integration (YOLO, Faster R-CNN)
- Person re-identification
- Multi-camera support
- Cloud connectivity for remote monitoring
- Mobile app for alerts

## References
- Digital Image Processing (Gonzalez & Woods)
- OpenCV Documentation: https://docs.opencv.org/
- Background Subtraction: Piccardi (2004)
- Canny Edge Detection: Canny (1986)

## License
Educational project for Image Processing course.

## Author
[Your Name]
[Your Student ID]
[Your University]

---

**Date**: January 2025
**Version**: 1.0
**Course**: Image Processing (Xá»­ LÃ½ áº¢nh)
```

---

## Thá»±c Hiá»‡n Theo CÃ¡c Phase

### Phase 1: Chuáº©n Bá»‹ MÃ´i TrÆ°á»ng (1-2 giá»)
1. âœ… Táº¡o folder structure
2. âœ… Setup virtual environment
3. âœ… Install dependencies
4. âœ… Prepare test videos
5. âœ… Create initial config files

### Phase 2: Implement Core Modules (4-6 giá»)
1. âœ… `motion_detector.py` - Frame differencing + MOG2
2. âœ… `adaptive_threshold.py` - Adaptive thresholding
3. âœ… `edge_detector.py` - Sobel + Canny
4. âœ… `region_grower.py` - Region growing
5. âœ… `intrusion_detector.py` - ROI overlap detection
6. âœ… `alert_system.py` - Visual/audio alerts + logging

### Phase 3: Integration (2-3 giá»)
1. âœ… `main.py` - Pipeline integration
2. âœ… Testing vá»›i real videos
3. âœ… Parameter tuning
4. âœ… Bug fixes

### Phase 4: Documentation - Theory (3-4 giá»)
1. âœ… Write 6 theory documents trong `01-theory-foundation/`
2. âœ… Add diagrams vÃ  examples
3. âœ… Cross-reference vá»›i code

### Phase 5: Documentation - Practice (2-3 giá»)
1. âœ… System architecture diagram
2. âœ… Algorithm design documentation
3. âœ… Implementation details explanation
4. âœ… User guide

### Phase 6: Evaluation (2-3 giá»)
1. âœ… Run tests in 3 lighting conditions
2. âœ… Collect metrics (accuracy, FPS, etc.)
3. âœ… Record demo videos
4. âœ… Analyze limitations

### Phase 7: Knowledge Base (3-4 giá»)
1. âœ… Write fundamental concepts (9 documents)
2. âœ… Add code examples
3. âœ… Create reference materials

### Phase 8: Implementation Guide (2-3 giá»)
1. âœ… Environment setup guide
2. âœ… Data preparation guide
3. âœ… Configuration guide
4. âœ… Troubleshooting guide

### Phase 9: Final Deliverables (2-3 giá»)
1. âœ… Compile final report PDF
2. âœ… Prepare demo videos vá»›i annotations
3. âœ… Create screenshots
4. âœ… Final code review vÃ  cleanup

### Phase 10: Testing & QA (1-2 giá»)
1. âœ… Run full system test
2. âœ… Verify all documentation links
3. âœ… Ensure reproducibility
4. âœ… Final presentation slides (optional)

---

## Estimated Total Time: 22-33 giá»

### Breakdown:
- **Code Implementation**: 8-11 giá» (35-40%)
- **Documentation**: 12-17 giá» (50-55%)
- **Testing & QA**: 2-5 giá» (10-15%)

---

## Success Criteria

### Code (35%):
- [ ] All modules implemented vÃ  functional
- [ ] System runs without errors
- [ ] Real-time processing (>20 FPS)
- [ ] Configurable parameters
- [ ] Clean, documented code

### Documentation (40%):
- [ ] Complete theory foundation (6 documents)
- [ ] Practical implementation guide (5 documents)
- [ ] Evaluation report vá»›i metrics (5 documents)
- [ ] Final report compiled (PDF)

### Deliverables (25%):
- [ ] 3 demo videos (daylight, low-light, night)
- [ ] Screenshots of system
- [ ] Alert logs
- [ ] Accuracy analysis report

---

## YÃªu Cáº§u BÃ¡o CÃ¡o

Theo format chuáº©n, bÃ¡o cÃ¡o cuá»‘i ká»³ cáº§n bao gá»“m:

### 1. CÆ¡ Sá»Ÿ LÃ½ Thuyáº¿t (Theory Foundation)
**Folder**: `documentation/01-theory-foundation/`

- [ ] Giáº£i thÃ­ch cÃ¡c thuáº­t toÃ¡n sá»­ dá»¥ng
- [ ] CÃ´ng thá»©c toÃ¡n há»c
- [ ] Diagrams vÃ  flowcharts
- [ ] References to textbooks/papers

### 2. Thá»±c HÃ nh (Practical Implementation)
**Folder**: `documentation/02-practical-implementation/`

- [ ] System architecture
- [ ] Algorithm design
- [ ] Implementation details
- [ ] Parameter tuning
- [ ] User guide

### 3. ÄÃ¡nh GiÃ¡ & Káº¿t Luáº­n (Evaluation & Conclusion)
**Folder**: `documentation/03-evaluation/`

- [ ] Test scenarios
- [ ] Accuracy metrics
- [ ] Performance analysis
- [ ] Limitations vÃ  challenges
- [ ] Conclusions

### 4. Sáº£n Pháº©m (Deliverables)
**Folder**: `documentation/04-deliverables/`

- [ ] Demo videos
- [ ] Screenshots
- [ ] Final report PDF
- [ ] Source code (vá»›i README)

---

## Checklist HoÃ n ThÃ nh

### TrÆ°á»›c Khi Báº¯t Äáº§u:
- [ ] Äá»c ká»¹ yÃªu cáº§u Ä‘á» tÃ i
- [ ] Chuáº©n bá»‹ video input samples
- [ ] XÃ¡c Ä‘á»‹nh ROI (restricted areas)
- [ ] Setup development environment

### Trong QuÃ¡ TrÃ¬nh:
- [ ] Commit code thÆ°á»ng xuyÃªn (Git)
- [ ] Test tá»«ng module riÃªng láº» trÆ°á»›c khi integrate
- [ ] Document code báº±ng docstrings
- [ ] Save intermediate results (screenshots, videos)

### TrÆ°á»›c Khi Ná»™p:
- [ ] Run full system test
- [ ] Verify táº¥t cáº£ file paths Ä‘Ãºng
- [ ] Check spelling vÃ  grammar trong documentation
- [ ] Compile final report PDF
- [ ] Create backup (zip archive)

---

## Tips & Best Practices

### Code:
1. **Modular design**: Má»—i module lÃ m 1 viá»‡c cá»¥ thá»ƒ
2. **Configuration file**: KhÃ´ng hardcode parameters
3. **Error handling**: Try-except cho file I/O, video capture
4. **Logging**: Use Python logging module, khÃ´ng chá»‰ print()
5. **Performance**: Profile code, optimize bottlenecks

### Documentation:
1. **Clear structure**: Headings, subheadings, bullet points
2. **Visuals**: Diagrams > text khi cÃ³ thá»ƒ
3. **Examples**: Code snippets vá»›i comments
4. **Cross-reference**: Link giá»¯a cÃ¡c documents
5. **Consistent format**: Markdown hoáº·c LaTeX

### Testing:
1. **Multiple videos**: Test nhiá»u scenarios
2. **Edge cases**: Very dark, very bright, fast motion, no motion
3. **Parameter sweep**: Try different configs
4. **Baseline comparison**: Compare vá»›i simple methods
5. **User testing**: Ask someone else to run your code

---

## Resources

### Learning Materials:
- **knowledge-base/**: Táº¥t cáº£ concepts cáº§n thiáº¿t
- **OpenCV Tutorials**: https://docs.opencv.org/4.x/d9/df8/tutorial_root.html
- **Gonzalez & Woods**: Digital Image Processing (Chapter 10: Image Segmentation)

### Sample Datasets:
- **VIRAT Video Dataset**: Surveillance videos
- **ChangeDetection.net**: Background subtraction benchmark
- **Pexels/Pixabay**: Free stock videos

### Tools:
- **ROI Selector**: `tools/roi_selector.py` (trong code)
- **Video Annotation**: LabelImg, CVAT
- **Performance Profiling**: cProfile, line_profiler

---

## Contact & Support

Náº¿u gáº·p váº¥n Ä‘á»:
1. Check `implementation-guide/6-troubleshooting.md`
2. Review `knowledge-base/` for concepts
3. Test individual modules in `tests/`
4. Check code examples trong theory documents

---

**Good luck vá»›i Ä‘á» tÃ i! ðŸŽ“ðŸš€**
