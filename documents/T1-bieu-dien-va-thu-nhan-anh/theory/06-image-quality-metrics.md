# L√Ω thuy·∫øt: C√°c ch·ªâ s·ªë ƒê√°nh gi√° Ch·∫•t l∆∞·ª£ng ·∫¢nh (Image Quality Metrics)

## 1. Gi·ªõi thi·ªáu

ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ·∫£nh c·∫ßn thi·∫øt ƒë·ªÉ:
- So s√°nh thu·∫≠t to√°n x·ª≠ l√Ω ·∫£nh
- ƒê√°nh gi√° m·ª©c ƒë·ªô n√©n
- ƒêo l∆∞·ªùng nhi·ªÖu v√† suy gi·∫£m
- T·ªëi ∆∞u h√≥a parameters

**Ph√¢n lo·∫°i**:
- **Full-reference**: C·∫ßn ·∫£nh g·ªëc (reference)
- **Reduced-reference**: C·∫ßn m·ªôt s·ªë ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh g·ªëc
- **No-reference**: Kh√¥ng c·∫ßn ·∫£nh g·ªëc (blind quality assessment)

## 2. MAE (Mean Absolute Error)

### 2.1. ƒê·ªãnh nghƒ©a
```
MAE = (1 / MN) √ó Œ£·µ¢ Œ£‚±º |I(i,j) - K(i,j)|
```

Trong ƒë√≥:
- I: ·∫¢nh g·ªëc
- K: ·∫¢nh test
- M√óN: K√≠ch th∆∞·ªõc ·∫£nh

### 2.2. Code
```python
def mae(img1, img2):
    return np.mean(np.abs(img1.astype(np.float32) - img2.astype(np.float32)))
```

### 2.3. ƒê·∫∑c ƒëi·ªÉm

**∆Øu ƒëi·ªÉm**:
- ƒê∆°n gi·∫£n, d·ªÖ hi·ªÉu
- ƒê∆°n v·ªã: gi√° tr·ªã pixel (0-255 cho 8-bit)
- Tuy·∫øn t√≠nh v·ªõi sai s·ªë

**Nh∆∞·ª£c ƒëi·ªÉm**:
- Kh√¥ng nh·∫°y v·ªõi perceptual quality
- T·∫•t c·∫£ pixel c√≥ tr·ªçng s·ªë b·∫±ng nhau
- Kh√¥ng x√©t c·∫•u tr√∫c ·∫£nh

**Gi√° tr·ªã**:
- MAE = 0: Hai ·∫£nh gi·ªëng h·ªát
- MAE < 5: R·∫•t t·ªët
- MAE < 10: T·ªët
- MAE > 20: K√©m

## 3. MSE (Mean Squared Error)

### 3.1. ƒê·ªãnh nghƒ©a
```
MSE = (1 / MN) √ó Œ£·µ¢ Œ£‚±º (I(i,j) - K(i,j))¬≤
```

### 3.2. Code
```python
def mse(img1, img2):
    return np.mean((img1.astype(np.float32) - img2.astype(np.float32))**2)
```

### 3.3. ƒê·∫∑c ƒëi·ªÉm

**∆Øu ƒëi·ªÉm**:
- C∆° s·ªü to√°n h·ªçc m·∫°nh
- Differentiable (d√πng cho optimization)
- Ph·∫°t n·∫∑ng outliers (do b√¨nh ph∆∞∆°ng)

**Nh∆∞·ª£c ƒëi·ªÉm**:
- ƒê∆°n v·ªã: pixel¬≤ (kh√≥ interpret)
- R·∫•t nh·∫°y v·ªõi outliers
- Kh√¥ng t∆∞∆°ng quan t·ªët v·ªõi human perception

**So s√°nh MAE vs MSE**:
- MSE ph·∫°t n·∫∑ng sai s·ªë l·ªõn h∆°n MAE
- MAE robust h∆°n v·ªõi noise/outliers
- MSE d·ªÖ t√≠nh ƒë·∫°o h√†m h∆°n (gradient descent)

## 4. PSNR (Peak Signal-to-Noise Ratio)

### 4.1. ƒê·ªãnh nghƒ©a
```
PSNR = 10 √ó log‚ÇÅ‚ÇÄ(MAX¬≤ / MSE)
     = 20 √ó log‚ÇÅ‚ÇÄ(MAX) - 10 √ó log‚ÇÅ‚ÇÄ(MSE)
```

V·ªõi MAX = 255 cho ·∫£nh 8-bit:
```
PSNR = 20 √ó log‚ÇÅ‚ÇÄ(255) - 10 √ó log‚ÇÅ‚ÇÄ(MSE)
     ‚âà 48.13 - 10 √ó log‚ÇÅ‚ÇÄ(MSE)
```

### 4.2. Code
```python
def psnr(img1, img2, max_val=255):
    mse_val = mse(img1, img2)
    if mse_val == 0:
        return float('inf')
    return 20 * np.log10(max_val) - 10 * np.log10(mse_val)
```

### 4.3. ƒê·∫∑c ƒëi·ªÉm

**∆Øu ƒëi·ªÉm**:
- ƒê∆°n v·ªã: dB (decibel) - d·ªÖ so s√°nh
- Ph·ªï bi·∫øn, ti√™u chu·∫©n trong nghi√™n c·ª©u
- Logarithmic scale

**Nh∆∞·ª£c ƒëi·ªÉm**:
- D·ª±a tr√™n MSE ‚Üí kh√¥ng t∆∞∆°ng quan t·ªët v·ªõi human perception
- Kh√¥ng x√©t c·∫•u tr√∫c
- C√≥ th·ªÉ misleading v·ªõi texture/pattern

**Gi√° tr·ªã**:
- PSNR > 40 dB: Xu·∫•t s·∫Øc (g·∫ßn nh∆∞ kh√¥ng nh·∫≠n bi·∫øt ƒë∆∞·ª£c)
- PSNR 30-40 dB: T·ªët
- PSNR 20-30 dB: Ch·∫•p nh·∫≠n ƒë∆∞·ª£c
- PSNR < 20 dB: K√©m

### 4.4. V√≠ d·ª•
```
MSE = 100 ‚Üí PSNR = 28.13 dB (t·ªët)
MSE = 10  ‚Üí PSNR = 38.13 dB (r·∫•t t·ªët)
MSE = 1   ‚Üí PSNR = 48.13 dB (xu·∫•t s·∫Øc)
```

## 5. SSIM (Structural Similarity Index)

### 5.1. ƒê·ªãnh nghƒ©a
SSIM ƒëo s·ª± gi·ªëng nhau v·ªÅ c·∫•u tr√∫c gi·ªØa 2 ·∫£nh:

```
SSIM(x, y) = [l(x,y)]^Œ± √ó [c(x,y)]^Œ≤ √ó [s(x,y)]^Œ≥
```

V·ªõi Œ± = Œ≤ = Œ≥ = 1:
```
SSIM(x, y) = l(x,y) √ó c(x,y) √ó s(x,y)
```

**Ba th√†nh ph·∫ßn**:

**1. Luminance** (ƒë·ªô s√°ng):
```
l(x, y) = (2Œº‚ÇìŒº·µß + C‚ÇÅ) / (Œº‚Çì¬≤ + Œº·µß¬≤ + C‚ÇÅ)
```

**2. Contrast** (ƒë·ªô t∆∞∆°ng ph·∫£n):
```
c(x, y) = (2œÉ‚ÇìœÉ·µß + C‚ÇÇ) / (œÉ‚Çì¬≤ + œÉ·µß¬≤ + C‚ÇÇ)
```

**3. Structure** (c·∫•u tr√∫c):
```
s(x, y) = (œÉ‚Çì·µß + C‚ÇÉ) / (œÉ‚ÇìœÉ·µß + C‚ÇÉ)
```

**Form ƒë∆°n gi·∫£n**:
```
SSIM(x, y) = [(2Œº‚ÇìŒº·µß + C‚ÇÅ)(2œÉ‚Çì·µß + C‚ÇÇ)] / [(Œº‚Çì¬≤ + Œº·µß¬≤ + C‚ÇÅ)(œÉ‚Çì¬≤ + œÉ·µß¬≤ + C‚ÇÇ)]
```

V·ªõi:
- Œº: mean
- œÉ: standard deviation
- œÉ‚Çì·µß: covariance
- C‚ÇÅ, C‚ÇÇ: constants ƒë·ªÉ tr√°nh chia cho 0

### 5.2. Code
```python
from skimage.metrics import structural_similarity as ssim

ssim_value = ssim(img1, img2, data_range=255)
```

Ho·∫∑c custom:
```python
def ssim_simple(img1, img2):
    C1 = (0.01 * 255)**2
    C2 = (0.03 * 255)**2

    img1 = img1.astype(np.float64)
    img2 = img2.astype(np.float64)

    mu1 = img1.mean()
    mu2 = img2.mean()

    sigma1_sq = np.var(img1)
    sigma2_sq = np.var(img2)
    sigma12 = np.cov(img1.flat, img2.flat)[0,1]

    ssim = ((2*mu1*mu2 + C1) * (2*sigma12 + C2)) / \
           ((mu1**2 + mu2**2 + C1) * (sigma1_sq + sigma2_sq + C2))

    return ssim
```

### 5.3. ƒê·∫∑c ƒëi·ªÉm

**∆Øu ƒëi·ªÉm**:
- **Perceptually meaningful**: T∆∞∆°ng quan t·ªët v·ªõi human perception
- X√©t c·∫•u tr√∫c, kh√¥ng ch·ªâ pixel-wise error
- Symmetric: SSIM(x,y) = SSIM(y,x)
- Bounded: SSIM ‚àà [-1, 1], th∆∞·ªùng [0, 1]

**Nh∆∞·ª£c ƒëi·ªÉm**:
- Ph·ª©c t·∫°p h∆°n MSE/PSNR
- Ch·∫≠m h∆°n (c·∫ßn t√≠nh covariance)
- C·∫ßn ch·ªçn window size

**Gi√° tr·ªã**:
- SSIM = 1: Hai ·∫£nh gi·ªëng h·ªát
- SSIM > 0.95: R·∫•t t·ªët (kh√≥ nh·∫≠n bi·∫øt)
- SSIM > 0.90: T·ªët
- SSIM > 0.80: Ch·∫•p nh·∫≠n ƒë∆∞·ª£c
- SSIM < 0.80: K√©m

### 5.4. Local SSIM
SSIM th∆∞·ªùng t√≠nh local (sliding window):
```python
# Window size 11√ó11 l√† standard
ssim_map = ssim(img1, img2, win_size=11, full=True)
mean_ssim = ssim_map.mean()
```

## 6. NCC (Normalized Cross-Correlation)

### 6.1. ƒê·ªãnh nghƒ©a
```
NCC = Œ£·µ¢ Œ£‚±º [I(i,j) - Œº·µ¢][K(i,j) - Œº‚Çñ] / (œÉ·µ¢ √ó œÉ‚Çñ √ó MN)
```

Ho·∫∑c:
```
NCC = cov(I, K) / (œÉ·µ¢ √ó œÉ‚Çñ)
```

### 6.2. Code
```python
def ncc(img1, img2):
    img1 = img1.astype(np.float32)
    img2 = img2.astype(np.float32)

    # Normalize
    img1 = (img1 - img1.mean()) / (img1.std() + 1e-6)
    img2 = (img2 - img2.mean()) / (img2.std() + 1e-6)

    return np.mean(img1 * img2)
```

### 6.3. ƒê·∫∑c ƒëi·ªÉm

**∆Øu ƒëi·ªÉm**:
- B·∫•t bi·∫øn v·ªõi linear brightness/contrast changes
- ƒêo correlation, kh√¥ng ph·∫£i difference
- Gi√° tr·ªã [-1, 1]

**Nh∆∞·ª£c ƒëi·ªÉm**:
- Kh√¥ng ph·ªï bi·∫øn nh∆∞ SSIM
- Kh√¥ng x√©t structure explicitly

**Gi√° tr·ªã**:
- NCC = 1: Perfect positive correlation
- NCC = 0: No correlation
- NCC = -1: Perfect negative correlation

## 7. So s√°nh c√°c Metrics

### 7.1. B·∫£ng so s√°nh

| Metric | Range | Unit | Perceptual | Complexity | Speed |
|--------|-------|------|------------|------------|-------|
| MAE | [0, 255] | pixel | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| MSE | [0, 65025] | pixel¬≤ | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| PSNR | [0, ‚àû] dB | dB | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| SSIM | [-1, 1] | unitless | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| NCC | [-1, 1] | unitless | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

### 7.2. Correlation v·ªõi Human Perception

**T·ª´ t·ªët ‚Üí k√©m**:
```
SSIM > MS-SSIM > FSIM > PSNR > MSE > MAE
```

### 7.3. Use Cases

**MAE/MSE**:
- Quick comparison
- Optimization (gradient descent)
- Not for perceptual quality

**PSNR**:
- Academic papers (standard)
- Quick benchmark
- Compression evaluation

**SSIM**:
- Perceptual quality assessment
- Image processing algorithm comparison
- Preferred over PSNR

**NCC**:
- Template matching
- Registration
- When brightness/contrast varies

## 8. V√≠ d·ª• So s√°nh

### 8.1. Gaussian Noise
```
Original vs Gaussian(œÉ=15):
MAE  ‚âà 12
MSE  ‚âà 225
PSNR ‚âà 24.6 dB
SSIM ‚âà 0.85
```

### 8.2. JPEG Compression
```
Original vs JPEG(quality=30):
MAE  ‚âà 8
MSE  ‚âà 100
PSNR ‚âà 28.1 dB
SSIM ‚âà 0.90
```

**Observation**: SSIM cao h∆°n expected v√¨ JPEG gi·ªØ structure t·ªët d√π c√≥ artifacts.

### 8.3. Salt & Pepper Noise
```
Original vs Salt&Pepper(5%):
MAE  ‚âà 13
MSE  ‚âà 650  (outliers!)
PSNR ‚âà 20.0 dB (th·∫•p v√¨ MSE cao)
SSIM ‚âà 0.92 (cao v√¨ structure c√≤n)
```

**Observation**: PSNR misleading, SSIM ph·∫£n √°nh t·ªët h∆°n.

## 9. Best Practices

### 9.1. Ch·ªçn metric
```
Task: General quality ‚Üí SSIM
Task: Optimization ‚Üí MSE/PSNR
Task: Quick check ‚Üí PSNR
Task: Academic paper ‚Üí PSNR + SSIM
Task: Perceptual ‚Üí SSIM only
```

### 9.2. Reporting
Lu√¥n report c·∫£ PSNR v√† SSIM:
```
Method A: PSNR=30.5 dB, SSIM=0.92
Method B: PSNR=29.8 dB, SSIM=0.94
‚Üí Method B better (SSIM higher, perceptual)
```

### 9.3. Multiple metrics
```python
def evaluate_quality(img_ref, img_test):
    return {
        'mae': mae(img_ref, img_test),
        'mse': mse(img_ref, img_test),
        'psnr': psnr(img_ref, img_test),
        'ssim': ssim(img_ref, img_test, data_range=255),
        'ncc': ncc(img_ref, img_test)
    }
```

## 10. Advanced Metrics

### 10.1. MS-SSIM (Multi-Scale SSIM)
T√≠nh SSIM ·ªü nhi·ªÅu scales (resolutions):
- Better than SSIM
- More computationally expensive

### 10.2. FSIM (Feature Similarity Index)
D·ª±a tr√™n phase congruency v√† gradient magnitude:
- Very good perceptual correlation
- Complex to compute

### 10.3. VIF (Visual Information Fidelity)
Based on natural scene statistics

### 10.4. LPIPS (Learned Perceptual Image Patch Similarity)
S·ª≠ d·ª•ng deep learning:
- State-of-the-art perceptual metric
- Requires pre-trained network

## 11. Limitations

### 11.1. All metrics c√≥ h·∫°n ch·∫ø
- No single metric perfect
- Context matters
- Human subjective test still gold standard

### 11.2. Misleading cases
```
Case 1: Shift by 1 pixel
  ‚Üí MSE high, but perceptually similar

Case 2: Brightness change
  ‚Üí MSE high, but structure same

Case 3: JPEG artifacts
  ‚Üí PSNR ok, but visible blocking
```

## 12. Code Examples Chi Ti·∫øt

### 12.1. Implementation ƒë·∫ßy ƒë·ªß c√°c metrics
```python
import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
import matplotlib.pyplot as plt

def mae(img1, img2):
    """Mean Absolute Error"""
    return np.mean(np.abs(img1.astype(np.float32) - img2.astype(np.float32)))

def mse(img1, img2):
    """Mean Squared Error"""
    return np.mean((img1.astype(np.float32) - img2.astype(np.float32))**2)

def psnr_custom(img1, img2, max_val=255):
    """Peak Signal-to-Noise Ratio"""
    mse_val = mse(img1, img2)
    if mse_val == 0:
        return float('inf')
    return 20 * np.log10(max_val) - 10 * np.log10(mse_val)

def ncc(img1, img2):
    """Normalized Cross-Correlation"""
    img1 = img1.astype(np.float32)
    img2 = img2.astype(np.float32)

    # Normalize (zero mean, unit variance)
    img1_norm = (img1 - img1.mean()) / (img1.std() + 1e-6)
    img2_norm = (img2 - img2.mean()) / (img2.std() + 1e-6)

    return np.mean(img1_norm * img2_norm)

def comprehensive_evaluation(img_original, img_degraded):
    """ƒê√°nh gi√° ƒë·∫ßy ƒë·ªß ch·∫•t l∆∞·ª£ng ·∫£nh"""

    # Ensure same size and type
    assert img_original.shape == img_degraded.shape, "Images must have same shape"

    # Compute all metrics
    results = {
        'MAE': mae(img_original, img_degraded),
        'MSE': mse(img_original, img_degraded),
        'PSNR': psnr(img_original, img_degraded, data_range=255),
        'SSIM': ssim(img_original, img_degraded, data_range=255),
        'NCC': ncc(img_original, img_degraded)
    }

    # Print results
    print("=" * 50)
    print("Image Quality Metrics:")
    print("=" * 50)
    print(f"  MAE:  {results['MAE']:.2f} (lower is better)")
    print(f"  MSE:  {results['MSE']:.2f} (lower is better)")
    print(f"  PSNR: {results['PSNR']:.2f} dB (higher is better)")
    print(f"  SSIM: {results['SSIM']:.4f} (higher is better, max=1.0)")
    print(f"  NCC:  {results['NCC']:.4f} (higher is better, max=1.0)")

    # Interpret SSIM
    if results['SSIM'] > 0.95:
        quality = "Excellent"
    elif results['SSIM'] > 0.90:
        quality = "Good"
    elif results['SSIM'] > 0.80:
        quality = "Fair"
    else:
        quality = "Poor"

    print(f"\nOverall Quality (SSIM-based): {quality}")
    print("=" * 50)

    return results

# Example usage
if __name__ == "__main__":
    # Load images
    img_orig = cv2.imread('original.png', cv2.IMREAD_GRAYSCALE)
    img_degraded = cv2.imread('degraded.png', cv2.IMREAD_GRAYSCALE)

    # Evaluate
    results = comprehensive_evaluation(img_orig, img_degraded)
```

### 12.2. Comparing multiple degraded versions
```python
def compare_multiple_versions(original, versions_dict):
    """
    So s√°nh nhi·ªÅu phi√™n b·∫£n c·ªßa ·∫£nh

    Args:
        original: ·∫£nh g·ªëc
        versions_dict: dict {name: degraded_image}

    Returns:
        DataFrame v·ªõi k·∫øt qu·∫£
    """
    import pandas as pd

    results = []
    for name, img_deg in versions_dict.items():
        metrics = {
            'Version': name,
            'MAE': mae(original, img_deg),
            'MSE': mse(original, img_deg),
            'PSNR': psnr(original, img_deg, data_range=255),
            'SSIM': ssim(original, img_deg, data_range=255),
            'NCC': ncc(original, img_deg)
        }
        results.append(metrics)

    df = pd.DataFrame(results)

    # Sort by SSIM (best first)
    df = df.sort_values('SSIM', ascending=False)

    print("\nComparison Results:")
    print(df.to_string(index=False))

    return df

# Example
original = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)

versions = {
    'JPEG Q=90': cv2.imread('lena_jpeg90.jpg', cv2.IMREAD_GRAYSCALE),
    'JPEG Q=50': cv2.imread('lena_jpeg50.jpg', cv2.IMREAD_GRAYSCALE),
    'JPEG Q=10': cv2.imread('lena_jpeg10.jpg', cv2.IMREAD_GRAYSCALE),
    'Gaussian Blur': cv2.GaussianBlur(original, (5, 5), 0),
    'Resize 50%': cv2.resize(cv2.resize(original, (256, 256)), (512, 512))
}

df = compare_multiple_versions(original, versions)
```

**Output m·∫´u**:
```
Comparison Results:
     Version    MAE     MSE   PSNR   SSIM    NCC
  JPEG Q=90   2.34   12.45  37.18  0.985  0.992
Gaussian Blur 3.12   18.23  35.52  0.972  0.988
  Resize 50%  5.67   45.89  31.51  0.945  0.971
  JPEG Q=50   8.91  102.34  28.03  0.912  0.945
  JPEG Q=10  23.45  789.12  19.16  0.687  0.812
```

### 12.3. Visualizing SSIM map
```python
def visualize_ssim_map(img1, img2):
    """Hi·ªÉn th·ªã SSIM map ƒë·ªÉ th·∫•y v√πng n√†o b·ªã degraded nhi·ªÅu"""

    # Compute SSIM with full map
    ssim_score, ssim_map = ssim(img1, img2, data_range=255, full=True)

    # Normalize SSIM map to [0, 255] for display
    ssim_map_display = ((ssim_map + 1) / 2 * 255).astype(np.uint8)

    # Create difference map
    diff = cv2.absdiff(img1, img2)

    # Plot
    fig, axes = plt.subplots(2, 2, figsize=(12, 12))

    axes[0, 0].imshow(img1, cmap='gray')
    axes[0, 0].set_title('Original')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(img2, cmap='gray')
    axes[0, 1].set_title('Degraded')
    axes[0, 1].axis('off')

    axes[1, 0].imshow(ssim_map_display, cmap='jet')
    axes[1, 0].set_title(f'SSIM Map (Overall: {ssim_score:.4f})\nRed = Poor, Blue = Good')
    axes[1, 0].axis('off')

    axes[1, 1].imshow(diff, cmap='hot')
    axes[1, 1].set_title('Absolute Difference\nBright = High error')
    axes[1, 1].axis('off')

    plt.tight_layout()
    plt.savefig('ssim_analysis.png', dpi=150)
    print(f"SSIM Score: {ssim_score:.4f}")
    print("Saved: ssim_analysis.png")

# Example
img_orig = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)
img_jpeg = cv2.imread('lena_compressed.jpg', cv2.IMREAD_GRAYSCALE)
visualize_ssim_map(img_orig, img_jpeg)
```

### 12.4. Testing different noise types
```python
def test_metrics_with_noise(img, noise_type='gaussian', noise_level=25):
    """
    Test c√°c metrics v·ªõi different noise types

    noise_type: 'gaussian', 'salt_pepper', 'speckle'
    noise_level: sigma cho gaussian, percentage cho salt&pepper
    """
    H, W = img.shape

    if noise_type == 'gaussian':
        # Gaussian noise
        noise = np.random.normal(0, noise_level, (H, W))
        noisy = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    elif noise_type == 'salt_pepper':
        # Salt & Pepper noise
        noisy = img.copy()
        num_salt = int((noise_level / 100) * img.size / 2)
        coords = [np.random.randint(0, i-1, num_salt) for i in img.shape]
        noisy[coords[0], coords[1]] = 255  # Salt
        num_pepper = num_salt
        coords = [np.random.randint(0, i-1, num_pepper) for i in img.shape]
        noisy[coords[0], coords[1]] = 0  # Pepper

    elif noise_type == 'speckle':
        # Speckle noise
        noise = np.random.randn(H, W)
        noisy = img + img * noise * (noise_level / 100)
        noisy = np.clip(noisy, 0, 255).astype(np.uint8)

    # Compute metrics
    results = {
        'Noise Type': noise_type,
        'Noise Level': noise_level,
        'MAE': mae(img, noisy),
        'MSE': mse(img, noisy),
        'PSNR': psnr(img, noisy, data_range=255),
        'SSIM': ssim(img, noisy, data_range=255)
    }

    print(f"\n{noise_type.upper()} Noise (level={noise_level}):")
    for k, v in results.items():
        if isinstance(v, float):
            print(f"  {k}: {v:.2f}")
        else:
            print(f"  {k}: {v}")

    return noisy, results

# Test
img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)

noisy_gaussian, _ = test_metrics_with_noise(img, 'gaussian', 15)
noisy_sp, _ = test_metrics_with_noise(img, 'salt_pepper', 5)
noisy_speckle, _ = test_metrics_with_noise(img, 'speckle', 10)
```

**Observation**: SSIM cao h∆°n v·ªõi salt&pepper v√¨ structure v·∫´n c√≤n, d√π MSE cao.

## 13. Best Practices

### ‚úÖ N√™n l√†m

1. **Lu√¥n report c·∫£ PSNR v√† SSIM**
   ```python
   def report_quality(img_ref, img_test, method_name=""):
       """Report both PSNR and SSIM for complete assessment"""
       psnr_val = psnr(img_ref, img_test, data_range=255)
       ssim_val = ssim(img_ref, img_test, data_range=255)

       print(f"{method_name}:")
       print(f"  PSNR: {psnr_val:.2f} dB")
       print(f"  SSIM: {ssim_val:.4f}")

       return {'psnr': psnr_val, 'ssim': ssim_val}

   # Example
   report_quality(original, compressed, "JPEG Compression Q=80")
   ```
   **L√Ω do**: PSNR l√† standard, SSIM ph·∫£n √°nh perceptual quality t·ªët h∆°n.

2. **Normalize images tr∆∞·ªõc khi t√≠nh metrics**
   ```python
   def safe_compute_metrics(img1, img2):
       """Ensure images are properly normalized"""
       # Convert to same dtype
       img1 = img1.astype(np.float32)
       img2 = img2.astype(np.float32)

       # Check range
       if img1.max() <= 1.0:
           data_range = 1.0
       else:
           data_range = 255.0

       psnr_val = psnr(img1, img2, data_range=data_range)
       ssim_val = ssim(img1, img2, data_range=data_range)

       return psnr_val, ssim_val
   ```
   **L√Ω do**: Tr√°nh l·ªói do kh√°c data range ([0,1] vs [0,255]).

3. **S·ª≠ d·ª•ng SSIM map ƒë·ªÉ debug**
   ```python
   # Khi SSIM th·∫•p, d√πng map ƒë·ªÉ t√¨m v√πng b·ªã degraded
   ssim_score, ssim_map = ssim(img1, img2, full=True, data_range=255)

   # T√¨m v√πng c√≥ SSIM th·∫•p nh·∫•t
   min_ssim_regions = ssim_map < 0.7

   # Visualize
   plt.imshow(min_ssim_regions, cmap='hot')
   plt.title('Degraded Regions (SSIM < 0.7)')
   ```
   **L√Ω do**: Gi√∫p hi·ªÉu degradation ·ªü ƒë√¢u, kh√¥ng ch·ªâ overall score.

4. **Ch·ªçn metric ph√π h·ª£p v·ªõi task**
   ```python
   # Compression evaluation
   metrics_compression = ['PSNR', 'SSIM', 'file_size']

   # Denoising evaluation
   metrics_denoising = ['PSNR', 'SSIM', 'edge_preservation']

   # Super-resolution evaluation
   metrics_sr = ['PSNR', 'SSIM', 'LPIPS', 'perceptual_loss']
   ```
   **L√Ω do**: M·ªói task c√≥ metrics ph√π h·ª£p ri√™ng.

### ‚ùå Kh√¥ng n√™n l√†m

1. **Kh√¥ng ch·ªâ d·ª±a v√†o PSNR**
   ```python
   # ‚ùå SAI - Ch·ªâ xem PSNR
   if psnr(img1, img2) > 30:
       print("Good quality")

   # ‚úÖ ƒê√öNG - Xem c·∫£ SSIM
   psnr_val = psnr(img1, img2, data_range=255)
   ssim_val = ssim(img1, img2, data_range=255)

   if psnr_val > 30 and ssim_val > 0.9:
       print("Good quality")
   ```
   **L√Ω do**: PSNR c√≥ th·ªÉ misleading (e.g., blur c√≥ PSNR cao nh∆∞ng tr√¥ng x·∫•u).

2. **Kh√¥ng so s√°nh ·∫£nh kh√°c k√≠ch th∆∞·ªõc**
   ```python
   # ‚ùå SAI - Kh√¥ng check size
   psnr_val = psnr(img1, img2)  # Error n·∫øu kh√°c size!

   # ‚úÖ ƒê√öNG - Check v√† resize n·∫øu c·∫ßn
   def safe_psnr(img1, img2):
       if img1.shape != img2.shape:
           print(f"Warning: Resizing img2 from {img2.shape} to {img1.shape}")
           img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))

       return psnr(img1, img2, data_range=255)
   ```

3. **Kh√¥ng qu√™n data_range parameter**
   ```python
   # ‚ùå SAI - Qu√™n data_range
   ssim_val = ssim(img1, img2)  # M·∫∑c ƒë·ªãnh data_range=255, c√≥ th·ªÉ sai n·∫øu ·∫£nh [0,1]

   # ‚úÖ ƒê√öNG
   if img1.max() <= 1.0:
       ssim_val = ssim(img1, img2, data_range=1.0)
   else:
       ssim_val = ssim(img1, img2, data_range=255)
   ```

4. **Kh√¥ng d√πng MSE/MAE l√†m perceptual metric**
   ```python
   # ‚ùå SAI - D√πng MSE ƒë·ªÉ ƒë√°nh gi√° user perception
   if mse(img1, img2) < 100:
       print("Looks good to user")  # Kh√¥ng ch√≠nh x√°c!

   # ‚úÖ ƒê√öNG - D√πng SSIM
   if ssim(img1, img2, data_range=255) > 0.9:
       print("Looks good to user")  # Ch√≠nh x√°c h∆°n
   ```

### üí° Tips

1. **PSNR threshold rules of thumb**
   ```
   PSNR > 40 dB: Imperceptible (kh√¥ng th·∫•y kh√°c bi·ªát)
   PSNR 30-40 dB: Perceptible but acceptable (th·∫•y nh∆∞ng ch·∫•p nh·∫≠n ƒë∆∞·ª£c)
   PSNR 20-30 dB: Noticeable degradation (degradation r√µ r√†ng)
   PSNR < 20 dB: Poor quality (ch·∫•t l∆∞·ª£ng k√©m)
   ```

2. **SSIM interpretation**
   ```
   SSIM > 0.99: Visually identical (h·∫ßu nh∆∞ gi·ªëng h·ªát)
   SSIM > 0.95: Excellent (xu·∫•t s·∫Øc)
   SSIM > 0.90: Good (t·ªët)
   SSIM > 0.80: Acceptable (ch·∫•p nh·∫≠n ƒë∆∞·ª£c)
   SSIM < 0.80: Poor (k√©m)
   ```

3. **Quick metric selection**
   ```python
   def suggest_metric(task):
       suggestions = {
           'compression': ['PSNR', 'SSIM', 'MS-SSIM'],
           'denoising': ['PSNR', 'SSIM'],
           'super_resolution': ['PSNR', 'SSIM', 'LPIPS'],
           'style_transfer': ['LPIPS', 'perceptual_loss'],
           'deblurring': ['PSNR', 'SSIM', 'sharpness'],
           'inpainting': ['SSIM', 'LPIPS'],
           'enhancement': ['SSIM', 'NIQE', 'BRISQUE']  # No-reference
       }
       return suggestions.get(task, ['PSNR', 'SSIM'])

   print(suggest_metric('compression'))  # ['PSNR', 'SSIM', 'MS-SSIM']
   ```

4. **Batch evaluation**
   ```python
   def batch_evaluate(ref_folder, test_folder):
       """Evaluate all images in folders"""
       ref_images = sorted(glob.glob(f"{ref_folder}/*.png"))
       test_images = sorted(glob.glob(f"{test_folder}/*.png"))

       results = []
       for ref_path, test_path in zip(ref_images, test_images):
           img_ref = cv2.imread(ref_path, cv2.IMREAD_GRAYSCALE)
           img_test = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)

           psnr_val = psnr(img_ref, img_test, data_range=255)
           ssim_val = ssim(img_ref, img_test, data_range=255)

           results.append({
               'image': os.path.basename(ref_path),
               'psnr': psnr_val,
               'ssim': ssim_val
           })

       df = pd.DataFrame(results)
       print(f"\nAverage PSNR: {df['psnr'].mean():.2f} dB")
       print(f"Average SSIM: {df['ssim'].mean():.4f}")

       return df
   ```

## 14. Common Pitfalls

### L·ªói 1: Qu√™n convert color images
**V·∫•n ƒë·ªÅ**:
```python
# Load color image
img1 = cv2.imread('photo1.jpg')  # BGR, shape (H, W, 3)
img2 = cv2.imread('photo2.jpg')

# Compute SSIM - L·ªñI! ssim expects 2D
ssim_val = ssim(img1, img2)  # Error ho·∫∑c k·∫øt qu·∫£ sai!
```

**Nguy√™n nh√¢n**: ssim m·∫∑c ƒë·ªãnh cho grayscale (2D). Color c·∫ßn x·ª≠ l√Ω ri√™ng.

**Gi·∫£i ph√°p**:
```python
# Option 1: Convert to grayscale
img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
ssim_val = ssim(img1_gray, img2_gray, data_range=255)

# Option 2: SSIM per channel, then average
ssim_per_channel = []
for i in range(3):
    ssim_c = ssim(img1[:,:,i], img2[:,:,i], data_range=255)
    ssim_per_channel.append(ssim_c)
ssim_val = np.mean(ssim_per_channel)

# Option 3: Use multichannel parameter (scikit-image)
ssim_val = ssim(img1, img2, data_range=255, channel_axis=2)
```

### L·ªói 2: PSNR = inf khi images gi·ªëng h·ªát
**V·∫•n ƒë·ªÅ**:
```python
img1 = cv2.imread('test.png')
img2 = img1.copy()

psnr_val = psnr(img1, img2)
print(psnr_val)  # inf !
```

**Nguy√™n nh√¢n**: MSE = 0 ‚Üí PSNR = log(0) = inf

**Gi·∫£i ph√°p**:
```python
def safe_psnr(img1, img2, max_val=255):
    """PSNR with handling for identical images"""
    mse_val = mse(img1, img2)

    if mse_val == 0:
        return float('inf')  # Ho·∫∑c return m·ªôt gi√° tr·ªã l·ªõn nh∆∞ 100

    return 20 * np.log10(max_val) - 10 * np.log10(mse_val)

# Ho·∫∑c handle khi report
psnr_val = psnr(img1, img2)
if np.isinf(psnr_val):
    print("PSNR: Perfect (identical images)")
else:
    print(f"PSNR: {psnr_val:.2f} dB")
```

### L·ªói 3: So s√°nh metrics gi·ªØa datasets kh√°c nhau
**V·∫•n ƒë·ªÅ**:
```python
# Dataset A: Natural photos
psnr_A = 35.2 dB

# Dataset B: Text/documents
psnr_B = 32.1 dB

# K·∫æT LU·∫¨N SAI: A t·ªët h∆°n B
```

**Nguy√™n nh√¢n**: C√°c lo·∫°i ·∫£nh kh√°c nhau c√≥ sensitivity kh√°c nhau v·ªõi degradation.

**Gi·∫£i ph√°p**:
```python
# Ch·ªâ so s√°nh trong c√πng 1 dataset
# Ho·∫∑c normalize based on baseline

def normalized_metric(test_psnr, baseline_psnr):
    """Normalize metric relative to baseline"""
    improvement = test_psnr - baseline_psnr
    return improvement

# Dataset A
improvement_A = normalized_metric(35.2, 30.0)  # +5.2 dB

# Dataset B
improvement_B = normalized_metric(32.1, 26.5)  # +5.6 dB

# B actually improved more!
```

### L·ªói 4: Kh√¥ng xem SSIM map khi debug
**V·∫•n ƒë·ªÅ**:
```python
ssim_val = ssim(img1, img2, data_range=255)
print(f"SSIM: {ssim_val:.4f}")  # 0.7500

# T·∫†I SAO th·∫•p? Kh√¥ng bi·∫øt!
```

**Gi·∫£i ph√°p**:
```python
# Always get the map when SSIM is low
ssim_val, ssim_map = ssim(img1, img2, data_range=255, full=True)

print(f"SSIM: {ssim_val:.4f}")

# Visualize map to find problem regions
plt.figure(figsize=(12, 4))

plt.subplot(131)
plt.imshow(img1, cmap='gray')
plt.title('Original')

plt.subplot(132)
plt.imshow(img2, cmap='gray')
plt.title('Degraded')

plt.subplot(133)
plt.imshow(ssim_map, cmap='jet')
plt.title('SSIM Map\n(Red=bad, Blue=good)')
plt.colorbar()

plt.tight_layout()
plt.show()

# B√¢y gi·ªù th·∫•y v√πng n√†o b·ªã degraded!
```

### L·ªói 5: S·ª≠ d·ª•ng metrics cho wrong purpose
**V·∫•n ƒë·ªÅ**:
```python
# D√πng PSNR ƒë·ªÉ optimize perceptual quality
loss = mse_loss(output, target)  # MSE ‚Üí PSNR
# K·∫øt qu·∫£: Blur nh∆∞ng PSNR cao!
```

**Nguy√™n nh√¢n**: PSNR kh√¥ng t∆∞∆°ng quan t·ªët v·ªõi human perception.

**Gi·∫£i ph√°p**:
```python
# Use perceptual loss for perceptual tasks
import lpips

loss_fn = lpips.LPIPS(net='alex')  # Perceptual loss
loss = loss_fn(output, target)

# Ho·∫∑c combined loss
loss_total = 0.5 * mse_loss + 0.5 * perceptual_loss
```

## 15. B√†i t·∫≠p Th·ª±c h√†nh

### B√†i 1: Implement v√† Compare Metrics
**ƒê·ªÅ b√†i**: Implement 4 metrics (MAE, MSE, PSNR, SSIM) t·ª´ scratch v√† so s√°nh v·ªõi scikit-image.

**Y√™u c·∫ßu**:
- T·ª± implement c√¥ng th·ª©c
- So s√°nh k·∫øt qu·∫£ v·ªõi library functions
- Test v·ªõi 3 lo·∫°i degradation: Gaussian blur, JPEG compression, Gaussian noise

**G·ª£i √Ω**:
```python
class ImageQualityMetrics:
    def __init__(self):
        pass

    def mae(self, img1, img2):
        # TODO: Implement
        pass

    def mse(self, img1, img2):
        # TODO: Implement
        pass

    def psnr(self, img1, img2, max_val=255):
        # TODO: Use self.mse()
        pass

    def ssim_simple(self, img1, img2):
        # TODO: Implement simplified SSIM (without sliding window)
        # Hint: Compute on whole image
        pass

# Test
metrics = ImageQualityMetrics()
img1 = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)
img2 = cv2.GaussianBlur(img1, (5, 5), 0)

print("Custom implementations:")
print(f"MAE:  {metrics.mae(img1, img2):.2f}")
print(f"MSE:  {metrics.mse(img1, img2):.2f}")
print(f"PSNR: {metrics.psnr(img1, img2):.2f} dB")

print("\nLibrary functions:")
from skimage.metrics import mean_squared_error
print(f"MSE:  {mean_squared_error(img1, img2):.2f}")
```

<details>
<summary>G·ª£i √Ω implementation MAE</summary>

```python
def mae(self, img1, img2):
    return np.mean(np.abs(img1.astype(np.float32) - img2.astype(np.float32)))
```
</details>

### B√†i 2: SSIM vs PSNR Disagreement
**ƒê·ªÅ b√†i**: T√¨m tr∆∞·ªùng h·ª£p PSNR cao nh∆∞ng SSIM th·∫•p (v√† ng∆∞·ª£c l·∫°i).

**Y√™u c·∫ßu**:
- T·∫°o 2 degraded versions t·ª´ 1 ·∫£nh g·ªëc:
  - Version A: PSNR cao, SSIM th·∫•p h∆°n
  - Version B: SSIM cao, PSNR th·∫•p h∆°n
- Gi·∫£i th√≠ch t·∫°i sao

**G·ª£i √Ω**:
```python
img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)

# Hint:
# - Gaussian blur: High PSNR, moderate SSIM (pixel values similar, structure blurred)
# - Salt&Pepper noise: Low PSNR (outliers), moderate SSIM (structure preserved)

# TODO: Create version_A and version_B
# TODO: Compute and compare metrics
# TODO: Visualize
```

<details>
<summary>G·ª£i √Ω chi ti·∫øt</summary>

- **High PSNR, Low SSIM**: Blur (pixel values c√≤n g·∫ßn, nh∆∞ng c·∫•u tr√∫c m·∫•t)
- **Low PSNR, High SSIM**: Salt & Pepper noise (outliers l√†m MSE cao, nh∆∞ng structure c√≤n)
</details>

### B√†i 3: Metric-based Algorithm Selection
**ƒê·ªÅ b√†i**: Cho 3 denoising algorithms, ch·ªçn best d·ª±a tr√™n metrics.

**Y√™u c·∫ßu**:
- Add Gaussian noise (œÉ=25) v√†o ·∫£nh
- Denoise b·∫±ng 3 methods:
  1. Gaussian blur (5√ó5)
  2. Median filter (5√ó5)
  3. Bilateral filter
- T√≠nh PSNR, SSIM cho m·ªói method
- Ch·ªçn best method
- Visualize k·∫øt qu·∫£

**G·ª£i √Ω**:
```python
import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim

# Load v√† add noise
img_clean = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)
noise = np.random.normal(0, 25, img_clean.shape)
img_noisy = np.clip(img_clean + noise, 0, 255).astype(np.uint8)

# Denoise methods
denoised_gaussian = cv2.GaussianBlur(img_noisy, (5, 5), 0)
denoised_median = cv2.medianBlur(img_noisy, 5)
denoised_bilateral = cv2.bilateralFilter(img_noisy, 9, 75, 75)

# TODO: Compute PSNR, SSIM for each
# TODO: Rank methods
# TODO: Visualize

# Expected: Bilateral should win on SSIM (preserves edges)
```

## 16. T√≥m t·∫Øt

**Key Takeaways**:
1. **SSIM is king** for perceptual quality
2. **PSNR for standard** comparison (but not perfect)
3. **Use multiple metrics** for comprehensive evaluation
4. **MSE/MAE for optimization**, not final assessment
5. **Context matters**: Choose metric based on application

**Quick Reference**:
```
Best perceptual:     SSIM > PSNR
Fastest:             MAE ‚âà MSE ‚âà PSNR
Standard in papers:  PSNR + SSIM
For optimization:    MSE
```

---

**References**:
- Wang et al. - "Image Quality Assessment: From Error Visibility to Structural Similarity" (2004)
- Gonzalez & Woods - Digital Image Processing
- Scikit-image Documentation
