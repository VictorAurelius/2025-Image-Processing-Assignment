# L√Ω Thuy·∫øt 5: Perspective Transform v√† Geometric Correction

## üìã T·ªïng Quan

**Perspective Transform** (ph√©p bi·∫øn ƒë·ªïi ph·ªëi c·∫£nh) cho ph√©p "s·ª≠a" g√≥c nh√¨n c·ªßa ·∫£nh - t·ª´ g√≥c xi√™n sang g√≥c vu√¥ng. ƒê√¢y l√† k·ªπ thu·∫≠t quan tr·ªçng trong:
- Document scanning
- Image rectification
- Augmented Reality
- Camera calibration

## üéØ ·ª®ng D·ª•ng

- **B√†i 2**: Document scanning (4 ƒëi·ªÉm g√≥c ‚Üí A4 th·∫≥ng)
- **B√†i 10**: Document deskew (xoay v·ªÅ 0¬∞)

## üìê To√°n H·ªçc Perspective Transform

### Homography Matrix

Perspective transform ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng ma tr·∫≠n 3√ó3 (homography):

```
[x']   [h11 h12 h13]   [x]
[y'] = [h21 h22 h23] √ó [y]
[w']   [h31 h32 h33]   [1]
```

Sau ƒë√≥ normalize:
```
x_output = x' / w'
y_output = y' / w'
```

### T√¨m Ma Tr·∫≠n Homography

C·∫ßn **4 c·∫∑p ƒëi·ªÉm t∆∞∆°ng ·ª©ng**:
- `src_pts`: 4 ƒëi·ªÉm tr√™n ·∫£nh g·ªëc
- `dst_pts`: 4 ƒëi·ªÉm t∆∞∆°ng ·ª©ng tr√™n ·∫£nh ƒë√≠ch

```python
M = cv2.getPerspectiveTransform(src_pts, dst_pts)
```

## üîß S·ª≠ D·ª•ng Trong OpenCV

### B∆∞·ªõc 1: T√¨m 4 ƒêi·ªÉm G√≥c

#### Ph∆∞∆°ng Ph√°p 1: T·ª± ƒê·ªông (Contours)

```python
# 1. Edges
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray, (5,5), 1.0)
edges = cv2.Canny(blur, 50, 150)

# 2. Dilate ƒë·ªÉ n·ªëi bi√™n
kernel = np.ones((5,5), np.uint8)
dilated = cv2.dilate(edges, kernel, iterations=1)

# 3. T√¨m contours
cnts, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 4. Ch·ªçn contour l·ªõn nh·∫•t (gi·∫•y)
cnt = max(cnts, key=cv2.contourArea)

# 5. X·∫•p x·ªâ th√†nh 4 ƒëi·ªÉm (h√¨nh ch·ªØ nh·∫≠t)
epsilon = 0.02 * cv2.arcLength(cnt, True)
approx = cv2.approxPolyDP(cnt, epsilon, True)

if len(approx) == 4:
    pts = approx.reshape(4, 2)
else:
    print("Kh√¥ng t√¨m th·∫•y 4 g√≥c!")
```

#### Ph∆∞∆°ng Ph√°p 2: Th·ªß C√¥ng (Mouse Click)

```python
pts = []

def click_event(event, x, y, flags, params):
    if event == cv2.EVENT_LBUTTONDOWN:
        pts.append([x, y])
        cv2.circle(img, (x, y), 5, (0,0,255), -1)
        cv2.imshow('Image', img)
        if len(pts) == 4:
            cv2.destroyAllWindows()

cv2.imshow('Image', img)
cv2.setMouseCallback('Image', click_event)
cv2.waitKey(0)

pts = np.array(pts, dtype=np.float32)
```

### B∆∞·ªõc 2: S·∫Øp X·∫øp 4 ƒêi·ªÉm

**Th·ª© t·ª± chu·∫©n**: Top-Left, Top-Right, Bottom-Right, Bottom-Left

```python
def order_points(pts):
    """
    S·∫Øp x·∫øp 4 ƒëi·ªÉm theo th·ª© t·ª±: TL, TR, BR, BL
    """
    rect = np.zeros((4, 2), dtype=np.float32)

    # T·ªïng: TL c√≥ t·ªïng nh·ªè nh·∫•t, BR c√≥ t·ªïng l·ªõn nh·∫•t
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # Top-Left
    rect[2] = pts[np.argmax(s)]  # Bottom-Right

    # Hi·ªáu: TR c√≥ hi·ªáu nh·ªè nh·∫•t, BL c√≥ hi·ªáu l·ªõn nh·∫•t
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # Top-Right
    rect[3] = pts[np.argmax(diff)]  # Bottom-Left

    return rect
```

### B∆∞·ªõc 3: T√≠nh K√≠ch Th∆∞·ªõc Output

```python
def compute_output_size(pts):
    """
    T√≠nh width v√† height c·ªßa ·∫£nh output
    """
    (tl, tr, br, bl) = pts

    # Width: Max c·ªßa c·∫°nh tr√™n v√† c·∫°nh d∆∞·ªõi
    width_top = np.linalg.norm(tr - tl)
    width_bottom = np.linalg.norm(br - bl)
    max_width = int(max(width_top, width_bottom))

    # Height: Max c·ªßa c·∫°nh tr√°i v√† c·∫°nh ph·∫£i
    height_left = np.linalg.norm(bl - tl)
    height_right = np.linalg.norm(br - tr)
    max_height = int(max(height_left, height_right))

    return max_width, max_height
```

**Ho·∫∑c c·ªë ƒë·ªãnh k√≠ch th∆∞·ªõc** (v√≠ d·ª• A4):
```python
# A4 ratio: 210mm √ó 297mm ‚âà 1:1.414
width = 600
height = int(width * 1.414)  # 848
```

### B∆∞·ªõc 4: T·∫°o Destination Points

```python
dst_pts = np.array([
    [0, 0],                    # Top-Left
    [width - 1, 0],            # Top-Right
    [width - 1, height - 1],   # Bottom-Right
    [0, height - 1]            # Bottom-Left
], dtype=np.float32)
```

### B∆∞·ªõc 5: Perspective Transform

```python
# T√≠nh ma tr·∫≠n homography
M = cv2.getPerspectiveTransform(src_pts, dst_pts)

# √Åp d·ª•ng transform
warped = cv2.warpPerspective(img, M, (width, height))
```

## üß™ V√≠ D·ª• Ho√†n Ch·ªânh: Document Scanning

```python
import cv2
import numpy as np

def order_points(pts):
    rect = np.zeros((4, 2), dtype=np.float32)
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(img, pts):
    # S·∫Øp x·∫øp ƒëi·ªÉm
    rect = order_points(pts)
    (tl, tr, br, bl) = rect

    # T√≠nh k√≠ch th∆∞·ªõc output
    width_top = np.linalg.norm(tr - tl)
    width_bottom = np.linalg.norm(br - bl)
    max_width = int(max(width_top, width_bottom))

    height_left = np.linalg.norm(bl - tl)
    height_right = np.linalg.norm(br - tr)
    max_height = int(max(height_left, height_right))

    # Destination points
    dst = np.array([
        [0, 0],
        [max_width - 1, 0],
        [max_width - 1, max_height - 1],
        [0, max_height - 1]
    ], dtype=np.float32)

    # Perspective transform
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(img, M, (max_width, max_height))

    return warped

# S·ª≠ d·ª•ng
img = cv2.imread('document.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray, (5,5), 1.0)
edges = cv2.Canny(blur, 50, 150)

# Morphology
kernel = np.ones((5,5), np.uint8)
dilated = cv2.dilate(edges, kernel)

# Contours
cnts, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnt = max(cnts, key=cv2.contourArea)

# Approximation
epsilon = 0.02 * cv2.arcLength(cnt, True)
approx = cv2.approxPolyDP(cnt, epsilon, True)

if len(approx) == 4:
    pts = approx.reshape(4, 2).astype(np.float32)
    warped = four_point_transform(img, pts)
    cv2.imwrite('scanned.jpg', warped)
```

## üîÑ Rotation Correction (Deskew)

### Ph√°t Hi·ªán G√≥c Nghi√™ng

#### Ph∆∞∆°ng Ph√°p 1: Hough Lines

```python
# T√¨m c√°c ƒë∆∞·ªùng th·∫≥ng
edges = cv2.Canny(gray, 50, 150)
lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)

# T√≠nh g√≥c trung b√¨nh
angles = []
for x1, y1, x2, y2 in lines[:,0]:
    angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
    angles.append(angle)

median_angle = np.median(angles)
```

#### Ph∆∞∆°ng Ph√°p 2: MinAreaRect

```python
# T√¨m contour c·ªßa vƒÉn b·∫£n
_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
cnts, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnt = max(cnts, key=cv2.contourArea)

# Rotated bounding box
rect = cv2.minAreaRect(cnt)
angle = rect[2]

# Chu·∫©n ho√° g√≥c v·ªÅ [-45, 45]
if angle < -45:
    angle = 90 + angle
```

### Xoay ·∫¢nh

```python
def rotate_image(img, angle):
    h, w = img.shape[:2]
    center = (w // 2, h // 2)

    # Ma tr·∫≠n xoay
    M = cv2.getRotationMatrix2D(center, angle, scale=1.0)

    # T√≠nh k√≠ch th∆∞·ªõc m·ªõi ƒë·ªÉ kh√¥ng crop
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])
    new_w = int(h * sin + w * cos)
    new_h = int(h * cos + w * sin)

    # ƒêi·ªÅu ch·ªânh translation
    M[0, 2] += (new_w / 2) - center[0]
    M[1, 2] += (new_h / 2) - center[1]

    # Xoay
    rotated = cv2.warpAffine(img, M, (new_w, new_h), flags=cv2.INTER_CUBIC,
                             borderMode=cv2.BORDER_REPLICATE)
    return rotated

# S·ª≠ d·ª•ng
rotated = rotate_image(img, -median_angle)
```

## üìä So S√°nh C√°c Lo·∫°i Transform

| Transform | Ma Tr·∫≠n | Tham S·ªë | B·∫£o To√†n | ·ª®ng D·ª•ng |
|-----------|---------|---------|----------|----------|
| **Translation** | 2√ó3 | (tx, ty) | G√≥c, kho·∫£ng c√°ch | Di chuy·ªÉn |
| **Rotation** | 2√ó3 | Œ∏ | G√≥c, kho·∫£ng c√°ch | Xoay |
| **Affine** | 2√ó3 | 3 ƒëi·ªÉm | ƒê∆∞·ªùng th·∫≥ng song song | Shear, scale |
| **Perspective** | 3√ó3 | 4 ƒëi·ªÉm | ƒê∆∞·ªùng th·∫≥ng | Document scan ‚≠ê |

## üî¨ ∆Øu Nh∆∞·ª£c ƒêi·ªÉm

### Perspective Transform - ∆Øu ƒêi·ªÉm
- ‚úÖ S·ª≠a m√©o ph·ªëi c·∫£nh ho√†n h·∫£o
- ‚úÖ Cho k·∫øt qu·∫£ "vu√¥ng g√≥c"
- ‚úÖ Chu·∫©n c√¥ng nghi·ªáp cho document scan
- ‚úÖ Linh ho·∫°t v·ªõi m·ªçi g√≥c ch·ª•p

### Perspective Transform - Nh∆∞·ª£c ƒêi·ªÉm
- ‚ùå C·∫ßn 4 ƒëi·ªÉm ch√≠nh x√°c
- ‚ùå Sai s·ªë ƒëi·ªÉm ‚Üí m√©o ·∫£nh
- ‚ùå Kh√¥ng t·ª± ƒë·ªông 100% (c·∫ßn detect g√≥c)
- ‚ùå C√≥ th·ªÉ m·∫•t ph·∫ßn ·∫£nh ngo√†i 4 ƒëi·ªÉm

## üöÄ K·ªπ Thu·∫≠t N√¢ng Cao

### 1. Interactive Point Selection

```python
import matplotlib.pyplot as plt

def select_points(img):
    fig, ax = plt.subplots()
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    pts = plt.ginput(4, timeout=0)  # Click 4 ƒëi·ªÉm
    plt.close()
    return np.array(pts, dtype=np.float32)

pts = select_points(img)
```

### 2. Auto-Detect v·ªõi Canny + Dilation

```python
# T√¨m c·∫°nh ngo√†i c√πng
edges = cv2.Canny(gray, 50, 150)
dilated = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=2)

# T√¨m contour l·ªõn nh·∫•t
cnts, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnt = max(cnts, key=cv2.contourArea)

# X·∫•p x·ªâ th√†nh h√¨nh ch·ªØ nh·∫≠t
peri = cv2.arcLength(cnt, True)
approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)

# TƒÉng epsilon n·∫øu kh√¥ng c√≥ 4 ƒëi·ªÉm
epsilon = 0.02
while len(approx) != 4 and epsilon < 0.1:
    epsilon += 0.01
    approx = cv2.approxPolyDP(cnt, epsilon * peri, True)
```

### 3. Border Removal

Sau transform, c·∫Øt b·ªè vi·ªÅn tr·∫Øng:

```python
gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)
_, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)

# T√¨m v√πng kh√¥ng tr·∫Øng
coords = cv2.findNonZero(thresh)
x, y, w, h = cv2.boundingRect(coords)

# Crop
cropped = warped[y:y+h, x:x+w]
```

## üß™ Debugging Tips

### 4 ƒêi·ªÉm Kh√¥ng ƒê√∫ng

```python
# Visualize c√°c ƒëi·ªÉm
for i, pt in enumerate(pts):
    cv2.circle(img, tuple(pt.astype(int)), 10, (0,255,0), -1)
    cv2.putText(img, str(i), tuple(pt.astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
cv2.imshow('Points', img)
cv2.waitKey(0)
```

### ·∫¢nh Output B·ªã M√©o

```python
# Ki·ªÉm tra th·ª© t·ª± ƒëi·ªÉm
rect = order_points(pts)
print("TL:", rect[0])
print("TR:", rect[1])
print("BR:", rect[2])
print("BL:", rect[3])

# V·∫Ω dest points ƒë·ªÉ x√°c nh·∫≠n
for i, pt in enumerate(dst_pts):
    cv2.circle(warped, tuple(pt.astype(int)), 5, (0,0,255), -1)
```

## üìö T√†i Li·ªáu Tham Kh·∫£o

- OpenCV Documentation: Geometric Transformations
- Hartley & Zisserman: Multiple View Geometry
- PyImageSearch: Document Scanner

## üîó Li√™n K·∫øt

**B√†i th·ª±c h√†nh**:
- **B√†i 2**: Document scanning (4-point transform)
- **B√†i 10**: Document deskew (rotation correction)

**L√Ω thuy·∫øt li√™n quan**:
- **02-canny-edge-detection.md**: T√¨m bi√™n cho detect g√≥c
- **04-contour-detection.md**: T√¨m contour gi·∫•y

---

**T√°c gi·∫£**: D·ª±a tr√™n PDF T21-40 T√°ch Bi√™n
**C·∫≠p nh·∫≠t**: 2025
